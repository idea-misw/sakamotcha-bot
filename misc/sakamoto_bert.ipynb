{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sakamoto_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok440ey5qnb1",
        "colab_type": "text"
      },
      "source": [
        "# SakamoBERTo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kt8TdV0XFo7",
        "colab_type": "text"
      },
      "source": [
        "Fine-tune a Japanese BERT model on a Sakamoto tweet classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_SY2z6yPzsR",
        "colab_type": "text"
      },
      "source": [
        "## Install Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNfAbCr5PSeo",
        "colab_type": "code",
        "outputId": "8dceddfd-98d8-4a7b-d772-213f957d9d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!cd transformers;pip install ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 26433 (delta 11), reused 19 (delta 7), pack-reused 26405\u001b[K\n",
            "Receiving objects: 100% (26433/26433), 15.87 MiB | 22.12 MiB/s, done.\n",
            "Resolving deltas: 100% (18417/18417), done.\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.18.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (0.14.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.9.1-cp36-none-any.whl size=637722 sha256=a31612578b8d41a5a8a9ac5738f84313d09abfd28efe566162470a63bb50c45c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dcu25m22/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=37a695edbfa7786744e0aebb7eda15e438bf3f9ad706ff2c1846e3fb63850de5\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KgFeuTjoU7i",
        "colab_type": "text"
      },
      "source": [
        "## Download CoLA data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHEBxTpQoV9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "# !python download_glue_data.py --data_dir glue_data --tasks all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4lZhZet20r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r drive/My\\ Drive/glue_data ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52OMOpp4tATI",
        "colab_type": "text"
      },
      "source": [
        "## Download a Japanese model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf5d3JaoqNr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "aad9d123-9d5b-4206-8a21-60bdb00dfb76"
      },
      "source": [
        "!wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip\n",
        "!unzip -d bert Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-16 05:07:38--  http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip\n",
            "Resolving nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)... 133.3.252.171\n",
            "Connecting to nlp.ist.i.kyoto-u.ac.jp (nlp.ist.i.kyoto-u.ac.jp)|133.3.252.171|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411573567 (393M) [application/zip]\n",
            "Saving to: ‘Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip’\n",
            "\n",
            "Japanese_L-12_H-768 100%[===================>] 392.51M   628KB/s    in 10m 52s \n",
            "\n",
            "2020-05-16 05:18:30 (617 KB/s) - ‘Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip’ saved [411573567/411573567]\n",
            "\n",
            "Archive:  Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip\n",
            "   creating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/\n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/config.json  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/pytorch_model.bin  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/tokenizer_config.json  \n",
            "  inflating: bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/vocab.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yz3FiaDqA-m",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjqKfim1vRuG",
        "colab_type": "code",
        "outputId": "b0909ae1-4580-41d4-90dd-61bcde322fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -U future\n",
        "!cd transformers;pip install -r ./examples/requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting future\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 4.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=ecd169c642f8cd9cb815c3f7cbec2ca9e0a100b2ba1b5b238590fa628026e645\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: future\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 7)) (2.1.0)\n",
            "Collecting pytorch-lightning==0.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/53/0549dd9c44c90e96d217592e094e9c53ef39ae2fed0c5cdb7e57aca65af6/pytorch_lightning-0.7.3-py3-none-any.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.6.0.post3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r ./examples/requirements.txt (line 3)) (2.3.1)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->-r ./examples/requirements.txt (line 5)) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score->-r ./examples/requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.21.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.18.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (19.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.3.1.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r ./examples/requirements.txt (line 8)) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.51.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.8)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=05da42ff86bda753dad2bc7e45e57855b699699ee76f9f6f2b4258221f9e51d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, pytorch-lightning\n",
            "Successfully installed portalocker-1.7.0 pytorch-lightning-0.7.3 rouge-score-0.0.3 sacrebleu-1.4.9 seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2TPpoORj83E",
        "colab_type": "code",
        "outputId": "827757ac-f9ad-4613-e945-3142ca26e2b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transformers/examples/text-classification/run_glue.py \\\n",
        "    --model_type bert \\\n",
        "    --model_name_or_path bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers \\\n",
        "    --task_name CoLA \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir glue_data/CoLA \\\n",
        "    --max_seq_length 128 \\\n",
        "    --per_gpu_eval_batch_size=8   \\\n",
        "    --per_gpu_train_batch_size=8   \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --output_dir sakamoto_bert"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-16 05:18:51.647441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/16/2020 05:18:53 - INFO - transformers.training_args -   PyTorch: setting up devices\n",
            "05/16/2020 05:18:53 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/16/2020 05:18:53 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='sakamoto_bert', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluate_during_training=False, per_gpu_train_batch_size=8, per_gpu_eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir=None, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False)\n",
            "05/16/2020 05:18:53 - INFO - transformers.configuration_utils -   loading configuration file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/config.json\n",
            "05/16/2020 05:18:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"cola\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32006\n",
            "}\n",
            "\n",
            "05/16/2020 05:18:53 - INFO - transformers.configuration_utils -   loading configuration file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/config.json\n",
            "05/16/2020 05:18:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 32006\n",
            "}\n",
            "\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   Model name 'bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   Didn't find file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/added_tokens.json. We won't load it.\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   Didn't find file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/special_tokens_map.json. We won't load it.\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   loading file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/vocab.txt\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/16/2020 05:18:53 - INFO - transformers.tokenization_utils -   loading file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/tokenizer_config.json\n",
            "05/16/2020 05:18:53 - INFO - transformers.modeling_utils -   loading weights file bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers/pytorch_model.bin\n",
            "05/16/2020 05:18:57 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "05/16/2020 05:18:57 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "05/16/2020 05:18:57 - INFO - filelock -   Lock 139803323194616 acquired on glue_data/CoLA/cached_train_BertTokenizer_128_cola.lock\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/CoLA\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   guid: train-0\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 5707, 29491, 22, 6537, 7070, 4848, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 1868, 10, 5469, 21047, 1920, 5, 3202, 8778, 30930, 14536, 16998, 4271, 314, 2281, 5, 8636, 938, 847, 9, 28464, 4320, 7779, 1953, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 5364, 750, 1566, 1566, 1566, 1566, 1566, 1566, 1566, 1566, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 15271, 6406, 5, 5145, 8, 1030, 683, 950, 3470, 6, 12507, 429, 20754, 5663, 8766, 1825, 3282, 710, 11, 10313, 104, 10313, 13, 2994, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "05/16/2020 05:18:57 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 10760, 1580, 90, 847, 13493, 642, 87, 27, 3202, 8778, 30930, 14536, 29850, 1868, 234, 276, 12, 5156, 3402, 6, 58, 3842, 8, 126, 2283, 12, 5156, 116, 27, 3202, 8778, 1124, 8778, 1275, 1183, 445, 4561, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/CoLA/cached_train_BertTokenizer_128_cola [took 0.485 s]\n",
            "05/16/2020 05:18:58 - INFO - filelock -   Lock 139803323194616 released on glue_data/CoLA/cached_train_BertTokenizer_128_cola.lock\n",
            "05/16/2020 05:18:58 - INFO - filelock -   Lock 139803608061096 acquired on glue_data/CoLA/cached_dev_BertTokenizer_128_cola.lock\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.datasets.glue -   Creating features from dataset file at glue_data/CoLA\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   guid: dev-0\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 6902, 9, 17437, 2148, 13473, 9, 504, 2222, 2771, 13, 28795, 943, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 2629, 273, 1, 19, 26242, 8069, 19, 26242, 22, 383, 1515, 6, 83, 26413, 2625, 6312, 361, 66, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 30872, 19, 47, 314, 3140, 4047, 387, 1, 1, 580, 1837, 1953, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 11247, 88, 397, 3714, 8, 21, 35, 50, 5, 15426, 801, 6, 6902, 5389, 9007, 14536, 1, 1713, 2382, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.processors.glue -   features: InputFeatures(input_ids=[2, 4245, 1825, 4503, 215, 5, 2179, 24682, 6941, 8, 59, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n",
            "05/16/2020 05:18:58 - INFO - transformers.data.datasets.glue -   Saving features into cached file glue_data/CoLA/cached_dev_BertTokenizer_128_cola [took 0.054 s]\n",
            "05/16/2020 05:18:58 - INFO - filelock -   Lock 139803608061096 released on glue_data/CoLA/cached_dev_BertTokenizer_128_cola.lock\n",
            "05/16/2020 05:18:58 - INFO - transformers.trainer -   You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -   ***** Running training *****\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Num examples = 2901\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Num Epochs = 3\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Instantaneous batch size per device = 8\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Gradient Accumulation steps = 1\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Total optimization steps = 1089\n",
            "05/16/2020 05:19:14 - INFO - transformers.trainer -     Starting fine-tuning.\n",
            "Epoch:   0% 0/3 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/363 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of addcdiv_ is deprecated:\n",
            "\taddcdiv_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcdiv_(Tensor tensor1, Tensor tensor2, *, Number value)\n",
            "\n",
            "Iteration:   0% 1/363 [00:00<03:04,  1.96it/s]\u001b[A\n",
            "Iteration:   1% 2/363 [00:00<02:23,  2.52it/s]\u001b[A\n",
            "Iteration:   1% 3/363 [00:00<01:54,  3.15it/s]\u001b[A\n",
            "Iteration:   1% 4/363 [00:00<01:33,  3.85it/s]\u001b[A\n",
            "Iteration:   1% 5/363 [00:01<01:18,  4.55it/s]\u001b[A\n",
            "Iteration:   2% 6/363 [00:01<01:08,  5.20it/s]\u001b[A\n",
            "Iteration:   2% 7/363 [00:01<01:01,  5.80it/s]\u001b[A\n",
            "Iteration:   2% 8/363 [00:01<00:56,  6.31it/s]\u001b[A\n",
            "Iteration:   2% 9/363 [00:01<00:52,  6.70it/s]\u001b[A\n",
            "Iteration:   3% 10/363 [00:01<00:50,  7.02it/s]\u001b[A\n",
            "Iteration:   3% 11/363 [00:01<00:48,  7.22it/s]\u001b[A\n",
            "Iteration:   3% 12/363 [00:01<00:48,  7.23it/s]\u001b[A\n",
            "Iteration:   4% 13/363 [00:02<00:47,  7.40it/s]\u001b[A\n",
            "Iteration:   4% 14/363 [00:02<00:46,  7.54it/s]\u001b[A\n",
            "Iteration:   4% 15/363 [00:02<00:45,  7.64it/s]\u001b[A\n",
            "Iteration:   4% 16/363 [00:02<00:44,  7.73it/s]\u001b[A\n",
            "Iteration:   5% 17/363 [00:02<00:44,  7.75it/s]\u001b[A\n",
            "Iteration:   5% 18/363 [00:02<00:44,  7.74it/s]\u001b[A\n",
            "Iteration:   5% 19/363 [00:02<00:44,  7.70it/s]\u001b[A\n",
            "Iteration:   6% 20/363 [00:02<00:44,  7.70it/s]\u001b[A\n",
            "Iteration:   6% 21/363 [00:03<00:44,  7.76it/s]\u001b[A\n",
            "Iteration:   6% 22/363 [00:03<00:43,  7.80it/s]\u001b[A\n",
            "Iteration:   6% 23/363 [00:03<00:43,  7.84it/s]\u001b[A\n",
            "Iteration:   7% 24/363 [00:03<00:42,  7.89it/s]\u001b[A\n",
            "Iteration:   7% 25/363 [00:03<00:43,  7.77it/s]\u001b[A\n",
            "Iteration:   7% 26/363 [00:03<00:43,  7.82it/s]\u001b[A\n",
            "Iteration:   7% 27/363 [00:03<00:43,  7.71it/s]\u001b[A\n",
            "Iteration:   8% 28/363 [00:03<00:43,  7.76it/s]\u001b[A\n",
            "Iteration:   8% 29/363 [00:04<00:43,  7.74it/s]\u001b[A\n",
            "Iteration:   8% 30/363 [00:04<00:42,  7.80it/s]\u001b[A\n",
            "Iteration:   9% 31/363 [00:04<00:42,  7.83it/s]\u001b[A\n",
            "Iteration:   9% 32/363 [00:04<00:42,  7.86it/s]\u001b[A\n",
            "Iteration:   9% 33/363 [00:04<00:41,  7.89it/s]\u001b[A\n",
            "Iteration:   9% 34/363 [00:04<00:41,  7.90it/s]\u001b[A\n",
            "Iteration:  10% 35/363 [00:04<00:42,  7.74it/s]\u001b[A\n",
            "Iteration:  10% 36/363 [00:05<00:43,  7.58it/s]\u001b[A\n",
            "Iteration:  10% 37/363 [00:05<00:42,  7.60it/s]\u001b[A\n",
            "Iteration:  10% 38/363 [00:05<00:42,  7.68it/s]\u001b[A\n",
            "Iteration:  11% 39/363 [00:05<00:41,  7.77it/s]\u001b[A\n",
            "Iteration:  11% 40/363 [00:05<00:41,  7.82it/s]\u001b[A\n",
            "Iteration:  11% 41/363 [00:05<00:41,  7.81it/s]\u001b[A\n",
            "Iteration:  12% 42/363 [00:05<00:41,  7.70it/s]\u001b[A\n",
            "Iteration:  12% 43/363 [00:05<00:41,  7.75it/s]\u001b[A\n",
            "Iteration:  12% 44/363 [00:06<00:41,  7.73it/s]\u001b[A\n",
            "Iteration:  12% 45/363 [00:06<00:41,  7.69it/s]\u001b[A\n",
            "Iteration:  13% 46/363 [00:06<00:40,  7.78it/s]\u001b[A\n",
            "Iteration:  13% 47/363 [00:06<00:40,  7.83it/s]\u001b[A\n",
            "Iteration:  13% 48/363 [00:06<00:40,  7.87it/s]\u001b[A\n",
            "Iteration:  13% 49/363 [00:06<00:40,  7.81it/s]\u001b[A\n",
            "Iteration:  14% 50/363 [00:06<00:40,  7.73it/s]\u001b[A\n",
            "Iteration:  14% 51/363 [00:06<00:40,  7.77it/s]\u001b[A\n",
            "Iteration:  14% 52/363 [00:07<00:39,  7.78it/s]\u001b[A\n",
            "Iteration:  15% 53/363 [00:07<00:39,  7.78it/s]\u001b[A\n",
            "Iteration:  15% 54/363 [00:07<00:39,  7.82it/s]\u001b[A\n",
            "Iteration:  15% 55/363 [00:07<00:39,  7.86it/s]\u001b[A\n",
            "Iteration:  15% 56/363 [00:07<00:38,  7.88it/s]\u001b[A\n",
            "Iteration:  16% 57/363 [00:07<00:39,  7.83it/s]\u001b[A\n",
            "Iteration:  16% 58/363 [00:07<00:39,  7.76it/s]\u001b[A\n",
            "Iteration:  16% 59/363 [00:07<00:38,  7.80it/s]\u001b[A\n",
            "Iteration:  17% 60/363 [00:08<00:38,  7.82it/s]\u001b[A\n",
            "Iteration:  17% 61/363 [00:08<00:38,  7.86it/s]\u001b[A\n",
            "Iteration:  17% 62/363 [00:08<00:38,  7.88it/s]\u001b[A\n",
            "Iteration:  17% 63/363 [00:08<00:37,  7.90it/s]\u001b[A\n",
            "Iteration:  18% 64/363 [00:08<00:38,  7.83it/s]\u001b[A\n",
            "Iteration:  18% 65/363 [00:08<00:37,  7.86it/s]\u001b[A\n",
            "Iteration:  18% 66/363 [00:08<00:38,  7.81it/s]\u001b[A\n",
            "Iteration:  18% 67/363 [00:08<00:37,  7.84it/s]\u001b[A\n",
            "Iteration:  19% 68/363 [00:09<00:37,  7.81it/s]\u001b[A\n",
            "Iteration:  19% 69/363 [00:09<00:37,  7.78it/s]\u001b[A\n",
            "Iteration:  19% 70/363 [00:09<00:37,  7.80it/s]\u001b[A\n",
            "Iteration:  20% 71/363 [00:09<00:37,  7.75it/s]\u001b[A\n",
            "Iteration:  20% 72/363 [00:09<00:37,  7.79it/s]\u001b[A\n",
            "Iteration:  20% 73/363 [00:09<00:36,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 74/363 [00:09<00:37,  7.63it/s]\u001b[A\n",
            "Iteration:  21% 75/363 [00:10<00:37,  7.70it/s]\u001b[A\n",
            "Iteration:  21% 76/363 [00:10<00:37,  7.70it/s]\u001b[A\n",
            "Iteration:  21% 77/363 [00:10<00:36,  7.78it/s]\u001b[A\n",
            "Iteration:  21% 78/363 [00:10<00:36,  7.80it/s]\u001b[A\n",
            "Iteration:  22% 79/363 [00:10<00:36,  7.81it/s]\u001b[A\n",
            "Iteration:  22% 80/363 [00:10<00:36,  7.77it/s]\u001b[A\n",
            "Iteration:  22% 81/363 [00:10<00:36,  7.82it/s]\u001b[A\n",
            "Iteration:  23% 82/363 [00:10<00:36,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 83/363 [00:11<00:35,  7.82it/s]\u001b[A\n",
            "Iteration:  23% 84/363 [00:11<00:35,  7.85it/s]\u001b[A\n",
            "Iteration:  23% 85/363 [00:11<00:35,  7.87it/s]\u001b[A\n",
            "Iteration:  24% 86/363 [00:11<00:35,  7.85it/s]\u001b[A\n",
            "Iteration:  24% 87/363 [00:11<00:35,  7.85it/s]\u001b[A\n",
            "Iteration:  24% 88/363 [00:11<00:34,  7.89it/s]\u001b[A\n",
            "Iteration:  25% 89/363 [00:11<00:34,  7.92it/s]\u001b[A\n",
            "Iteration:  25% 90/363 [00:11<00:34,  7.89it/s]\u001b[A\n",
            "Iteration:  25% 91/363 [00:12<00:34,  7.90it/s]\u001b[A\n",
            "Iteration:  25% 92/363 [00:12<00:34,  7.92it/s]\u001b[A\n",
            "Iteration:  26% 93/363 [00:12<00:34,  7.87it/s]\u001b[A\n",
            "Iteration:  26% 94/363 [00:12<00:34,  7.86it/s]\u001b[A\n",
            "Iteration:  26% 95/363 [00:12<00:34,  7.85it/s]\u001b[A\n",
            "Iteration:  26% 96/363 [00:12<00:33,  7.89it/s]\u001b[A\n",
            "Iteration:  27% 97/363 [00:12<00:33,  7.90it/s]\u001b[A\n",
            "Iteration:  27% 98/363 [00:12<00:33,  7.89it/s]\u001b[A\n",
            "Iteration:  27% 99/363 [00:13<00:33,  7.77it/s]\u001b[A\n",
            "Iteration:  28% 100/363 [00:13<00:33,  7.82it/s]\u001b[A\n",
            "Iteration:  28% 101/363 [00:13<00:33,  7.87it/s]\u001b[A\n",
            "Iteration:  28% 102/363 [00:13<00:33,  7.90it/s]\u001b[A\n",
            "Iteration:  28% 103/363 [00:13<00:32,  7.91it/s]\u001b[A\n",
            "Iteration:  29% 104/363 [00:13<00:32,  7.94it/s]\u001b[A\n",
            "Iteration:  29% 105/363 [00:13<00:32,  7.94it/s]\u001b[A\n",
            "Iteration:  29% 106/363 [00:13<00:32,  7.93it/s]\u001b[A\n",
            "Iteration:  29% 107/363 [00:14<00:32,  7.88it/s]\u001b[A\n",
            "Iteration:  30% 108/363 [00:14<00:32,  7.88it/s]\u001b[A\n",
            "Iteration:  30% 109/363 [00:14<00:32,  7.77it/s]\u001b[A\n",
            "Iteration:  30% 110/363 [00:14<00:32,  7.83it/s]\u001b[A\n",
            "Iteration:  31% 111/363 [00:14<00:32,  7.86it/s]\u001b[A\n",
            "Iteration:  31% 112/363 [00:14<00:31,  7.91it/s]\u001b[A\n",
            "Iteration:  31% 113/363 [00:14<00:32,  7.71it/s]\u001b[A\n",
            "Iteration:  31% 114/363 [00:14<00:31,  7.79it/s]\u001b[A\n",
            "Iteration:  32% 115/363 [00:15<00:31,  7.84it/s]\u001b[A\n",
            "Iteration:  32% 116/363 [00:15<00:31,  7.87it/s]\u001b[A\n",
            "Iteration:  32% 117/363 [00:15<00:32,  7.63it/s]\u001b[A\n",
            "Iteration:  33% 118/363 [00:15<00:31,  7.73it/s]\u001b[A\n",
            "Iteration:  33% 119/363 [00:15<00:31,  7.80it/s]\u001b[A\n",
            "Iteration:  33% 120/363 [00:15<00:31,  7.83it/s]\u001b[A\n",
            "Iteration:  33% 121/363 [00:15<00:30,  7.85it/s]\u001b[A\n",
            "Iteration:  34% 122/363 [00:16<00:30,  7.88it/s]\u001b[A\n",
            "Iteration:  34% 123/363 [00:16<00:30,  7.91it/s]\u001b[A\n",
            "Iteration:  34% 124/363 [00:16<00:30,  7.87it/s]\u001b[A\n",
            "Iteration:  34% 125/363 [00:16<00:30,  7.80it/s]\u001b[A\n",
            "Iteration:  35% 126/363 [00:16<00:30,  7.82it/s]\u001b[A\n",
            "Iteration:  35% 127/363 [00:16<00:30,  7.84it/s]\u001b[A\n",
            "Iteration:  35% 128/363 [00:16<00:29,  7.88it/s]\u001b[A\n",
            "Iteration:  36% 129/363 [00:16<00:29,  7.90it/s]\u001b[A\n",
            "Iteration:  36% 130/363 [00:17<00:29,  7.88it/s]\u001b[A\n",
            "Iteration:  36% 131/363 [00:17<00:29,  7.91it/s]\u001b[A\n",
            "Iteration:  36% 132/363 [00:17<00:29,  7.81it/s]\u001b[A\n",
            "Iteration:  37% 133/363 [00:17<00:29,  7.85it/s]\u001b[A\n",
            "Iteration:  37% 134/363 [00:17<00:29,  7.90it/s]\u001b[A\n",
            "Iteration:  37% 135/363 [00:17<00:28,  7.90it/s]\u001b[A\n",
            "Iteration:  37% 136/363 [00:17<00:29,  7.81it/s]\u001b[A\n",
            "Iteration:  38% 137/363 [00:17<00:28,  7.84it/s]\u001b[A\n",
            "Iteration:  38% 138/363 [00:18<00:28,  7.85it/s]\u001b[A\n",
            "Iteration:  38% 139/363 [00:18<00:28,  7.89it/s]\u001b[A\n",
            "Iteration:  39% 140/363 [00:18<00:28,  7.85it/s]\u001b[A\n",
            "Iteration:  39% 141/363 [00:18<00:28,  7.87it/s]\u001b[A\n",
            "Iteration:  39% 142/363 [00:18<00:27,  7.90it/s]\u001b[A\n",
            "Iteration:  39% 143/363 [00:18<00:27,  7.90it/s]\u001b[A\n",
            "Iteration:  40% 144/363 [00:18<00:27,  7.91it/s]\u001b[A\n",
            "Iteration:  40% 145/363 [00:18<00:27,  7.95it/s]\u001b[A\n",
            "Iteration:  40% 146/363 [00:19<00:27,  7.93it/s]\u001b[A\n",
            "Iteration:  40% 147/363 [00:19<00:27,  7.92it/s]\u001b[A\n",
            "Iteration:  41% 148/363 [00:19<00:27,  7.93it/s]\u001b[A\n",
            "Iteration:  41% 149/363 [00:19<00:26,  7.96it/s]\u001b[A\n",
            "Iteration:  41% 150/363 [00:19<00:26,  7.95it/s]\u001b[A\n",
            "Iteration:  42% 151/363 [00:19<00:27,  7.80it/s]\u001b[A\n",
            "Iteration:  42% 152/363 [00:19<00:26,  7.84it/s]\u001b[A\n",
            "Iteration:  42% 153/363 [00:19<00:26,  7.88it/s]\u001b[A\n",
            "Iteration:  42% 154/363 [00:20<00:26,  7.79it/s]\u001b[A\n",
            "Iteration:  43% 155/363 [00:20<00:27,  7.60it/s]\u001b[A\n",
            "Iteration:  43% 156/363 [00:20<00:26,  7.69it/s]\u001b[A\n",
            "Iteration:  43% 157/363 [00:20<00:26,  7.78it/s]\u001b[A\n",
            "Iteration:  44% 158/363 [00:20<00:26,  7.79it/s]\u001b[A\n",
            "Iteration:  44% 159/363 [00:20<00:25,  7.85it/s]\u001b[A\n",
            "Iteration:  44% 160/363 [00:20<00:25,  7.89it/s]\u001b[A\n",
            "Iteration:  44% 161/363 [00:20<00:25,  7.85it/s]\u001b[A\n",
            "Iteration:  45% 162/363 [00:21<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  45% 163/363 [00:21<00:25,  7.87it/s]\u001b[A\n",
            "Iteration:  45% 164/363 [00:21<00:25,  7.88it/s]\u001b[A\n",
            "Iteration:  45% 165/363 [00:21<00:25,  7.85it/s]\u001b[A\n",
            "Iteration:  46% 166/363 [00:21<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  46% 167/363 [00:21<00:24,  7.87it/s]\u001b[A\n",
            "Iteration:  46% 168/363 [00:21<00:24,  7.82it/s]\u001b[A\n",
            "Iteration:  47% 169/363 [00:21<00:25,  7.69it/s]\u001b[A\n",
            "Iteration:  47% 170/363 [00:22<00:25,  7.57it/s]\u001b[A\n",
            "Iteration:  47% 171/363 [00:22<00:24,  7.68it/s]\u001b[A\n",
            "Iteration:  47% 172/363 [00:22<00:24,  7.73it/s]\u001b[A\n",
            "Iteration:  48% 173/363 [00:22<00:24,  7.80it/s]\u001b[A\n",
            "Iteration:  48% 174/363 [00:22<00:24,  7.81it/s]\u001b[A\n",
            "Iteration:  48% 175/363 [00:22<00:23,  7.87it/s]\u001b[A\n",
            "Iteration:  48% 176/363 [00:22<00:23,  7.85it/s]\u001b[A\n",
            "Iteration:  49% 177/363 [00:23<00:23,  7.75it/s]\u001b[A\n",
            "Iteration:  49% 178/363 [00:23<00:23,  7.79it/s]\u001b[A\n",
            "Iteration:  49% 179/363 [00:23<00:23,  7.78it/s]\u001b[A\n",
            "Iteration:  50% 180/363 [00:23<00:23,  7.77it/s]\u001b[A\n",
            "Iteration:  50% 181/363 [00:23<00:23,  7.80it/s]\u001b[A\n",
            "Iteration:  50% 182/363 [00:23<00:23,  7.84it/s]\u001b[A\n",
            "Iteration:  50% 183/363 [00:23<00:23,  7.82it/s]\u001b[A\n",
            "Iteration:  51% 184/363 [00:23<00:23,  7.60it/s]\u001b[A\n",
            "Iteration:  51% 185/363 [00:24<00:23,  7.67it/s]\u001b[A\n",
            "Iteration:  51% 186/363 [00:24<00:22,  7.72it/s]\u001b[A\n",
            "Iteration:  52% 187/363 [00:24<00:22,  7.81it/s]\u001b[A\n",
            "Iteration:  52% 188/363 [00:24<00:22,  7.86it/s]\u001b[A\n",
            "Iteration:  52% 189/363 [00:24<00:22,  7.87it/s]\u001b[A\n",
            "Iteration:  52% 190/363 [00:24<00:22,  7.85it/s]\u001b[A\n",
            "Iteration:  53% 191/363 [00:24<00:21,  7.89it/s]\u001b[A\n",
            "Iteration:  53% 192/363 [00:24<00:21,  7.91it/s]\u001b[A\n",
            "Iteration:  53% 193/363 [00:25<00:21,  7.89it/s]\u001b[A\n",
            "Iteration:  53% 194/363 [00:25<00:21,  7.91it/s]\u001b[A\n",
            "Iteration:  54% 195/363 [00:25<00:21,  7.91it/s]\u001b[A\n",
            "Iteration:  54% 196/363 [00:25<00:21,  7.95it/s]\u001b[A\n",
            "Iteration:  54% 197/363 [00:25<00:20,  7.94it/s]\u001b[A\n",
            "Iteration:  55% 198/363 [00:25<00:20,  7.96it/s]\u001b[A\n",
            "Iteration:  55% 199/363 [00:25<00:20,  7.89it/s]\u001b[A\n",
            "Iteration:  55% 200/363 [00:25<00:20,  7.91it/s]\u001b[A\n",
            "Iteration:  55% 201/363 [00:26<00:20,  7.87it/s]\u001b[A\n",
            "Iteration:  56% 202/363 [00:26<00:20,  7.87it/s]\u001b[A\n",
            "Iteration:  56% 203/363 [00:26<00:20,  7.81it/s]\u001b[A\n",
            "Iteration:  56% 204/363 [00:26<00:20,  7.86it/s]\u001b[A\n",
            "Iteration:  56% 205/363 [00:26<00:20,  7.85it/s]\u001b[A\n",
            "Iteration:  57% 206/363 [00:26<00:19,  7.88it/s]\u001b[A\n",
            "Iteration:  57% 207/363 [00:26<00:19,  7.89it/s]\u001b[A\n",
            "Iteration:  57% 208/363 [00:26<00:19,  7.90it/s]\u001b[A\n",
            "Iteration:  58% 209/363 [00:27<00:19,  7.88it/s]\u001b[A\n",
            "Iteration:  58% 210/363 [00:27<00:19,  7.89it/s]\u001b[A\n",
            "Iteration:  58% 211/363 [00:27<00:19,  7.91it/s]\u001b[A\n",
            "Iteration:  58% 212/363 [00:27<00:19,  7.91it/s]\u001b[A\n",
            "Iteration:  59% 213/363 [00:27<00:18,  7.95it/s]\u001b[A\n",
            "Iteration:  59% 214/363 [00:27<00:18,  7.92it/s]\u001b[A\n",
            "Iteration:  59% 215/363 [00:27<00:18,  7.94it/s]\u001b[A\n",
            "Iteration:  60% 216/363 [00:27<00:18,  7.80it/s]\u001b[A\n",
            "Iteration:  60% 217/363 [00:28<00:19,  7.65it/s]\u001b[A\n",
            "Iteration:  60% 218/363 [00:28<00:19,  7.62it/s]\u001b[A\n",
            "Iteration:  60% 219/363 [00:28<00:18,  7.68it/s]\u001b[A\n",
            "Iteration:  61% 220/363 [00:28<00:18,  7.74it/s]\u001b[A\n",
            "Iteration:  61% 221/363 [00:28<00:18,  7.79it/s]\u001b[A\n",
            "Iteration:  61% 222/363 [00:28<00:18,  7.81it/s]\u001b[A\n",
            "Iteration:  61% 223/363 [00:28<00:17,  7.84it/s]\u001b[A\n",
            "Iteration:  62% 224/363 [00:29<00:17,  7.84it/s]\u001b[A\n",
            "Iteration:  62% 225/363 [00:29<00:17,  7.85it/s]\u001b[A\n",
            "Iteration:  62% 226/363 [00:29<00:17,  7.87it/s]\u001b[A\n",
            "Iteration:  63% 227/363 [00:29<00:17,  7.89it/s]\u001b[A\n",
            "Iteration:  63% 228/363 [00:29<00:17,  7.89it/s]\u001b[A\n",
            "Iteration:  63% 229/363 [00:29<00:17,  7.85it/s]\u001b[A\n",
            "Iteration:  63% 230/363 [00:29<00:16,  7.87it/s]\u001b[A\n",
            "Iteration:  64% 231/363 [00:29<00:16,  7.89it/s]\u001b[A\n",
            "Iteration:  64% 232/363 [00:30<00:16,  7.88it/s]\u001b[A\n",
            "Iteration:  64% 233/363 [00:30<00:16,  7.83it/s]\u001b[A\n",
            "Iteration:  64% 234/363 [00:30<00:16,  7.87it/s]\u001b[A\n",
            "Iteration:  65% 235/363 [00:30<00:16,  7.89it/s]\u001b[A\n",
            "Iteration:  65% 236/363 [00:30<00:16,  7.69it/s]\u001b[A\n",
            "Iteration:  65% 237/363 [00:30<00:16,  7.69it/s]\u001b[A\n",
            "Iteration:  66% 238/363 [00:30<00:16,  7.76it/s]\u001b[A\n",
            "Iteration:  66% 239/363 [00:30<00:15,  7.75it/s]\u001b[A\n",
            "Iteration:  66% 240/363 [00:31<00:15,  7.78it/s]\u001b[A\n",
            "Iteration:  66% 241/363 [00:31<00:15,  7.78it/s]\u001b[A\n",
            "Iteration:  67% 242/363 [00:31<00:15,  7.81it/s]\u001b[A\n",
            "Iteration:  67% 243/363 [00:31<00:15,  7.82it/s]\u001b[A\n",
            "Iteration:  67% 244/363 [00:31<00:15,  7.78it/s]\u001b[A\n",
            "Iteration:  67% 245/363 [00:31<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  68% 246/363 [00:31<00:14,  7.87it/s]\u001b[A\n",
            "Iteration:  68% 247/363 [00:31<00:14,  7.83it/s]\u001b[A\n",
            "Iteration:  68% 248/363 [00:32<00:14,  7.82it/s]\u001b[A\n",
            "Iteration:  69% 249/363 [00:32<00:14,  7.85it/s]\u001b[A\n",
            "Iteration:  69% 250/363 [00:32<00:14,  7.84it/s]\u001b[A\n",
            "Iteration:  69% 251/363 [00:32<00:14,  7.84it/s]\u001b[A\n",
            "Iteration:  69% 252/363 [00:32<00:14,  7.82it/s]\u001b[A\n",
            "Iteration:  70% 253/363 [00:32<00:13,  7.86it/s]\u001b[A\n",
            "Iteration:  70% 254/363 [00:32<00:13,  7.87it/s]\u001b[A\n",
            "Iteration:  70% 255/363 [00:32<00:13,  7.85it/s]\u001b[A\n",
            "Iteration:  71% 256/363 [00:33<00:13,  7.90it/s]\u001b[A\n",
            "Iteration:  71% 257/363 [00:33<00:13,  7.90it/s]\u001b[A\n",
            "Iteration:  71% 258/363 [00:33<00:13,  7.90it/s]\u001b[A\n",
            "Iteration:  71% 259/363 [00:33<00:13,  7.87it/s]\u001b[A\n",
            "Iteration:  72% 260/363 [00:33<00:13,  7.89it/s]\u001b[A\n",
            "Iteration:  72% 261/363 [00:33<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  72% 262/363 [00:33<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  72% 263/363 [00:33<00:12,  7.88it/s]\u001b[A\n",
            "Iteration:  73% 264/363 [00:34<00:12,  7.91it/s]\u001b[A\n",
            "Iteration:  73% 265/363 [00:34<00:12,  7.91it/s]\u001b[A\n",
            "Iteration:  73% 266/363 [00:34<00:12,  7.90it/s]\u001b[A\n",
            "Iteration:  74% 267/363 [00:34<00:12,  7.91it/s]\u001b[A\n",
            "Iteration:  74% 268/363 [00:34<00:11,  7.92it/s]\u001b[A\n",
            "Iteration:  74% 269/363 [00:34<00:11,  7.92it/s]\u001b[A\n",
            "Iteration:  74% 270/363 [00:34<00:11,  7.90it/s]\u001b[A\n",
            "Iteration:  75% 271/363 [00:34<00:11,  7.90it/s]\u001b[A\n",
            "Iteration:  75% 272/363 [00:35<00:11,  7.92it/s]\u001b[A\n",
            "Iteration:  75% 273/363 [00:35<00:11,  7.94it/s]\u001b[A\n",
            "Iteration:  75% 274/363 [00:35<00:11,  7.93it/s]\u001b[A\n",
            "Iteration:  76% 275/363 [00:35<00:11,  7.92it/s]\u001b[A\n",
            "Iteration:  76% 276/363 [00:35<00:10,  7.92it/s]\u001b[A\n",
            "Iteration:  76% 277/363 [00:35<00:10,  7.94it/s]\u001b[A\n",
            "Iteration:  77% 278/363 [00:35<00:10,  7.82it/s]\u001b[A\n",
            "Iteration:  77% 279/363 [00:36<00:10,  7.87it/s]\u001b[A\n",
            "Iteration:  77% 280/363 [00:36<00:10,  7.70it/s]\u001b[A\n",
            "Iteration:  77% 281/363 [00:36<00:10,  7.74it/s]\u001b[A\n",
            "Iteration:  78% 282/363 [00:36<00:10,  7.77it/s]\u001b[A\n",
            "Iteration:  78% 283/363 [00:36<00:10,  7.77it/s]\u001b[A\n",
            "Iteration:  78% 284/363 [00:36<00:10,  7.82it/s]\u001b[A\n",
            "Iteration:  79% 285/363 [00:36<00:10,  7.75it/s]\u001b[A\n",
            "Iteration:  79% 286/363 [00:36<00:09,  7.80it/s]\u001b[A\n",
            "Iteration:  79% 287/363 [00:37<00:09,  7.84it/s]\u001b[A\n",
            "Iteration:  79% 288/363 [00:37<00:09,  7.74it/s]\u001b[A\n",
            "Iteration:  80% 289/363 [00:37<00:09,  7.76it/s]\u001b[A\n",
            "Iteration:  80% 290/363 [00:37<00:09,  7.83it/s]\u001b[A\n",
            "Iteration:  80% 291/363 [00:37<00:09,  7.86it/s]\u001b[A\n",
            "Iteration:  80% 292/363 [00:37<00:09,  7.87it/s]\u001b[A\n",
            "Iteration:  81% 293/363 [00:37<00:09,  7.74it/s]\u001b[A\n",
            "Iteration:  81% 294/363 [00:37<00:08,  7.80it/s]\u001b[A\n",
            "Iteration:  81% 295/363 [00:38<00:08,  7.83it/s]\u001b[A\n",
            "Iteration:  82% 296/363 [00:38<00:08,  7.79it/s]\u001b[A\n",
            "Iteration:  82% 297/363 [00:38<00:08,  7.70it/s]\u001b[A\n",
            "Iteration:  82% 298/363 [00:38<00:08,  7.79it/s]\u001b[A\n",
            "Iteration:  82% 299/363 [00:38<00:08,  7.70it/s]\u001b[A\n",
            "Iteration:  83% 300/363 [00:38<00:08,  7.78it/s]\u001b[A\n",
            "Iteration:  83% 301/363 [00:38<00:08,  7.72it/s]\u001b[A\n",
            "Iteration:  83% 302/363 [00:38<00:07,  7.78it/s]\u001b[A\n",
            "Iteration:  83% 303/363 [00:39<00:07,  7.83it/s]\u001b[A\n",
            "Iteration:  84% 304/363 [00:39<00:07,  7.86it/s]\u001b[A\n",
            "Iteration:  84% 305/363 [00:39<00:07,  7.86it/s]\u001b[A\n",
            "Iteration:  84% 306/363 [00:39<00:07,  7.87it/s]\u001b[A\n",
            "Iteration:  85% 307/363 [00:39<00:07,  7.91it/s]\u001b[A\n",
            "Iteration:  85% 308/363 [00:39<00:06,  7.91it/s]\u001b[A\n",
            "Iteration:  85% 309/363 [00:39<00:06,  7.91it/s]\u001b[A\n",
            "Iteration:  85% 310/363 [00:39<00:06,  7.87it/s]\u001b[A\n",
            "Iteration:  86% 311/363 [00:40<00:06,  7.86it/s]\u001b[A\n",
            "Iteration:  86% 312/363 [00:40<00:06,  7.83it/s]\u001b[A\n",
            "Iteration:  86% 313/363 [00:40<00:06,  7.87it/s]\u001b[A\n",
            "Iteration:  87% 314/363 [00:40<00:06,  7.87it/s]\u001b[A\n",
            "Iteration:  87% 315/363 [00:40<00:06,  7.89it/s]\u001b[A\n",
            "Iteration:  87% 316/363 [00:40<00:05,  7.86it/s]\u001b[A\n",
            "Iteration:  87% 317/363 [00:40<00:05,  7.73it/s]\u001b[A\n",
            "Iteration:  88% 318/363 [00:41<00:05,  7.70it/s]\u001b[A\n",
            "Iteration:  88% 319/363 [00:41<00:05,  7.75it/s]\u001b[A\n",
            "Iteration:  88% 320/363 [00:41<00:05,  7.74it/s]\u001b[A\n",
            "Iteration:  88% 321/363 [00:41<00:05,  7.75it/s]\u001b[A\n",
            "Iteration:  89% 322/363 [00:41<00:05,  7.77it/s]\u001b[A\n",
            "Iteration:  89% 323/363 [00:41<00:05,  7.73it/s]\u001b[A\n",
            "Iteration:  89% 324/363 [00:41<00:05,  7.77it/s]\u001b[A\n",
            "Iteration:  90% 325/363 [00:41<00:04,  7.76it/s]\u001b[A\n",
            "Iteration:  90% 326/363 [00:42<00:04,  7.79it/s]\u001b[A\n",
            "Iteration:  90% 327/363 [00:42<00:04,  7.85it/s]\u001b[A\n",
            "Iteration:  90% 328/363 [00:42<00:04,  7.89it/s]\u001b[A\n",
            "Iteration:  91% 329/363 [00:42<00:04,  7.86it/s]\u001b[A\n",
            "Iteration:  91% 330/363 [00:42<00:04,  7.91it/s]\u001b[A\n",
            "Iteration:  91% 331/363 [00:42<00:04,  7.85it/s]\u001b[A\n",
            "Iteration:  91% 332/363 [00:42<00:03,  7.88it/s]\u001b[A\n",
            "Iteration:  92% 333/363 [00:42<00:03,  7.86it/s]\u001b[A\n",
            "Iteration:  92% 334/363 [00:43<00:03,  7.89it/s]\u001b[A\n",
            "Iteration:  92% 335/363 [00:43<00:03,  7.91it/s]\u001b[A\n",
            "Iteration:  93% 336/363 [00:43<00:03,  7.94it/s]\u001b[A\n",
            "Iteration:  93% 337/363 [00:43<00:03,  7.90it/s]\u001b[A\n",
            "Iteration:  93% 338/363 [00:43<00:03,  7.85it/s]\u001b[A\n",
            "Iteration:  93% 339/363 [00:43<00:03,  7.87it/s]\u001b[A\n",
            "Iteration:  94% 340/363 [00:43<00:02,  7.89it/s]\u001b[A\n",
            "Iteration:  94% 341/363 [00:43<00:02,  7.81it/s]\u001b[A\n",
            "Iteration:  94% 342/363 [00:44<00:02,  7.83it/s]\u001b[A\n",
            "Iteration:  94% 343/363 [00:44<00:02,  7.87it/s]\u001b[A\n",
            "Iteration:  95% 344/363 [00:44<00:02,  7.90it/s]\u001b[A\n",
            "Iteration:  95% 345/363 [00:44<00:02,  7.88it/s]\u001b[A\n",
            "Iteration:  95% 346/363 [00:44<00:02,  7.90it/s]\u001b[A\n",
            "Iteration:  96% 347/363 [00:44<00:02,  7.93it/s]\u001b[A\n",
            "Iteration:  96% 348/363 [00:44<00:01,  7.89it/s]\u001b[A\n",
            "Iteration:  96% 349/363 [00:44<00:01,  7.86it/s]\u001b[A\n",
            "Iteration:  96% 350/363 [00:45<00:01,  7.81it/s]\u001b[A\n",
            "Iteration:  97% 351/363 [00:45<00:01,  7.87it/s]\u001b[A\n",
            "Iteration:  97% 352/363 [00:45<00:01,  7.90it/s]\u001b[A\n",
            "Iteration:  97% 353/363 [00:45<00:01,  7.90it/s]\u001b[A\n",
            "Iteration:  98% 354/363 [00:45<00:01,  7.92it/s]\u001b[A\n",
            "Iteration:  98% 355/363 [00:45<00:01,  7.94it/s]\u001b[A\n",
            "Iteration:  98% 356/363 [00:45<00:00,  7.93it/s]\u001b[A\n",
            "Iteration:  98% 357/363 [00:45<00:00,  7.82it/s]\u001b[A\n",
            "Iteration:  99% 358/363 [00:46<00:00,  7.88it/s]\u001b[A\n",
            "Iteration:  99% 359/363 [00:46<00:00,  7.90it/s]\u001b[A\n",
            "Iteration:  99% 360/363 [00:46<00:00,  7.87it/s]\u001b[A\n",
            "Iteration:  99% 361/363 [00:46<00:00,  7.82it/s]\u001b[A\n",
            "Iteration: 100% 363/363 [00:46<00:00,  7.77it/s]\n",
            "Epoch:  33% 1/3 [00:46<01:33, 46.70s/it]\n",
            "Iteration:   0% 0/363 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/363 [00:00<00:45,  7.96it/s]\u001b[A\n",
            "Iteration:   1% 2/363 [00:00<00:45,  7.93it/s]\u001b[A\n",
            "Iteration:   1% 3/363 [00:00<00:45,  7.94it/s]\u001b[A\n",
            "Iteration:   1% 4/363 [00:00<00:45,  7.95it/s]\u001b[A\n",
            "Iteration:   1% 5/363 [00:00<00:44,  7.97it/s]\u001b[A\n",
            "Iteration:   2% 6/363 [00:00<00:45,  7.91it/s]\u001b[A\n",
            "Iteration:   2% 7/363 [00:00<00:44,  7.93it/s]\u001b[A\n",
            "Iteration:   2% 8/363 [00:01<00:44,  7.90it/s]\u001b[A\n",
            "Iteration:   2% 9/363 [00:01<00:44,  7.91it/s]\u001b[A\n",
            "Iteration:   3% 10/363 [00:01<00:45,  7.80it/s]\u001b[A\n",
            "Iteration:   3% 11/363 [00:01<00:44,  7.83it/s]\u001b[A\n",
            "Iteration:   3% 12/363 [00:01<00:44,  7.84it/s]\u001b[A\n",
            "Iteration:   4% 13/363 [00:01<00:44,  7.87it/s]\u001b[A\n",
            "Iteration:   4% 14/363 [00:01<00:44,  7.78it/s]\u001b[A\n",
            "Iteration:   4% 15/363 [00:01<00:44,  7.83it/s]\u001b[A\n",
            "Iteration:   4% 16/363 [00:02<00:44,  7.87it/s]\u001b[A\n",
            "Iteration:   5% 17/363 [00:02<00:43,  7.87it/s]\u001b[A\n",
            "Iteration:   5% 18/363 [00:02<00:43,  7.87it/s]\u001b[A\n",
            "Iteration:   5% 19/363 [00:02<00:43,  7.90it/s]\u001b[A\n",
            "Iteration:   6% 20/363 [00:02<00:43,  7.86it/s]\u001b[A\n",
            "Iteration:   6% 21/363 [00:02<00:43,  7.89it/s]\u001b[A\n",
            "Iteration:   6% 22/363 [00:02<00:43,  7.84it/s]\u001b[A\n",
            "Iteration:   6% 23/363 [00:02<00:43,  7.88it/s]\u001b[A\n",
            "Iteration:   7% 24/363 [00:03<00:42,  7.89it/s]\u001b[A\n",
            "Iteration:   7% 25/363 [00:03<00:42,  7.88it/s]\u001b[A\n",
            "Iteration:   7% 26/363 [00:03<00:43,  7.77it/s]\u001b[A\n",
            "Iteration:   7% 27/363 [00:03<00:42,  7.83it/s]\u001b[A\n",
            "Iteration:   8% 28/363 [00:03<00:42,  7.87it/s]\u001b[A\n",
            "Iteration:   8% 29/363 [00:03<00:42,  7.87it/s]\u001b[A\n",
            "Iteration:   8% 30/363 [00:03<00:42,  7.89it/s]\u001b[A\n",
            "Iteration:   9% 31/363 [00:03<00:41,  7.92it/s]\u001b[A\n",
            "Iteration:   9% 32/363 [00:04<00:41,  7.89it/s]\u001b[A\n",
            "Iteration:   9% 33/363 [00:04<00:42,  7.85it/s]\u001b[A\n",
            "Iteration:   9% 34/363 [00:04<00:41,  7.88it/s]\u001b[A\n",
            "Iteration:  10% 35/363 [00:04<00:41,  7.92it/s]\u001b[A\n",
            "Iteration:  10% 36/363 [00:04<00:41,  7.87it/s]\u001b[A\n",
            "Iteration:  10% 37/363 [00:04<00:41,  7.82it/s]\u001b[A\n",
            "Iteration:  10% 38/363 [00:04<00:41,  7.85it/s]\u001b[A\n",
            "Iteration:  11% 39/363 [00:04<00:41,  7.87it/s]\u001b[A\n",
            "Iteration:  11% 40/363 [00:05<00:41,  7.86it/s]\u001b[A\n",
            "Iteration:  11% 41/363 [00:05<00:41,  7.79it/s]\u001b[A\n",
            "Iteration:  12% 42/363 [00:05<00:41,  7.81it/s]\u001b[A\n",
            "Iteration:  12% 43/363 [00:05<00:40,  7.85it/s]\u001b[A\n",
            "Iteration:  12% 44/363 [00:05<00:40,  7.87it/s]\u001b[A\n",
            "Iteration:  12% 45/363 [00:05<00:40,  7.91it/s]\u001b[A\n",
            "Iteration:  13% 46/363 [00:05<00:39,  7.94it/s]\u001b[A\n",
            "Iteration:  13% 47/363 [00:05<00:39,  7.95it/s]\u001b[A\n",
            "Iteration:  13% 48/363 [00:06<00:40,  7.84it/s]\u001b[A\n",
            "Iteration:  13% 49/363 [00:06<00:39,  7.85it/s]\u001b[A\n",
            "Iteration:  14% 50/363 [00:06<00:39,  7.89it/s]\u001b[A\n",
            "Iteration:  14% 51/363 [00:06<00:39,  7.91it/s]\u001b[A\n",
            "Iteration:  14% 52/363 [00:06<00:39,  7.89it/s]\u001b[A\n",
            "Iteration:  15% 53/363 [00:06<00:39,  7.92it/s]\u001b[A\n",
            "Iteration:  15% 54/363 [00:06<00:38,  7.93it/s]\u001b[A\n",
            "Iteration:  15% 55/363 [00:06<00:38,  7.95it/s]\u001b[A\n",
            "Iteration:  15% 56/363 [00:07<00:39,  7.81it/s]\u001b[A\n",
            "Iteration:  16% 57/363 [00:07<00:39,  7.70it/s]\u001b[A\n",
            "Iteration:  16% 58/363 [00:07<00:39,  7.74it/s]\u001b[A\n",
            "Iteration:  16% 59/363 [00:07<00:38,  7.80it/s]\u001b[A\n",
            "Iteration:  17% 60/363 [00:07<00:38,  7.87it/s]\u001b[A\n",
            "Iteration:  17% 61/363 [00:07<00:38,  7.87it/s]\u001b[A\n",
            "Iteration:  17% 62/363 [00:07<00:38,  7.81it/s]\u001b[A\n",
            "Iteration:  17% 63/363 [00:08<00:38,  7.80it/s]\u001b[A\n",
            "Iteration:  18% 64/363 [00:08<00:38,  7.73it/s]\u001b[A\n",
            "Iteration:  18% 65/363 [00:08<00:38,  7.72it/s]\u001b[A\n",
            "Iteration:  18% 66/363 [00:08<00:38,  7.78it/s]\u001b[A\n",
            "Iteration:  18% 67/363 [00:08<00:37,  7.82it/s]\u001b[A\n",
            "Iteration:  19% 68/363 [00:08<00:37,  7.83it/s]\u001b[A\n",
            "Iteration:  19% 69/363 [00:08<00:37,  7.86it/s]\u001b[A\n",
            "Iteration:  19% 70/363 [00:08<00:37,  7.84it/s]\u001b[A\n",
            "Iteration:  20% 71/363 [00:09<00:37,  7.88it/s]\u001b[A\n",
            "Iteration:  20% 72/363 [00:09<00:37,  7.83it/s]\u001b[A\n",
            "Iteration:  20% 73/363 [00:09<00:37,  7.81it/s]\u001b[A\n",
            "Iteration:  20% 74/363 [00:09<00:37,  7.80it/s]\u001b[A\n",
            "Iteration:  21% 75/363 [00:09<00:36,  7.86it/s]\u001b[A\n",
            "Iteration:  21% 76/363 [00:09<00:36,  7.82it/s]\u001b[A\n",
            "Iteration:  21% 77/363 [00:09<00:36,  7.86it/s]\u001b[A\n",
            "Iteration:  21% 78/363 [00:09<00:36,  7.88it/s]\u001b[A\n",
            "Iteration:  22% 79/363 [00:10<00:35,  7.91it/s]\u001b[A\n",
            "Iteration:  22% 80/363 [00:10<00:36,  7.84it/s]\u001b[A\n",
            "Iteration:  22% 81/363 [00:10<00:35,  7.85it/s]\u001b[A\n",
            "Iteration:  23% 82/363 [00:10<00:35,  7.87it/s]\u001b[A\n",
            "Iteration:  23% 83/363 [00:10<00:35,  7.90it/s]\u001b[A\n",
            "Iteration:  23% 84/363 [00:10<00:35,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 85/363 [00:10<00:35,  7.86it/s]\u001b[A\n",
            "Iteration:  24% 86/363 [00:10<00:35,  7.83it/s]\u001b[A\n",
            "Iteration:  24% 87/363 [00:11<00:35,  7.84it/s]\u001b[A\n",
            "Iteration:  24% 88/363 [00:11<00:35,  7.79it/s]\u001b[A\n",
            "Iteration:  25% 89/363 [00:11<00:35,  7.80it/s]\u001b[A\n",
            "Iteration:  25% 90/363 [00:11<00:34,  7.83it/s]\u001b[A\n",
            "Iteration:  25% 91/363 [00:11<00:34,  7.83it/s]\u001b[A\n",
            "Iteration:  25% 92/363 [00:11<00:35,  7.72it/s]\u001b[A\n",
            "Iteration:  26% 93/363 [00:11<00:34,  7.74it/s]\u001b[A\n",
            "Iteration:  26% 94/363 [00:11<00:34,  7.77it/s]\u001b[A\n",
            "Iteration:  26% 95/363 [00:12<00:34,  7.82it/s]\u001b[A\n",
            "Iteration:  26% 96/363 [00:12<00:34,  7.82it/s]\u001b[A\n",
            "Iteration:  27% 97/363 [00:12<00:34,  7.76it/s]\u001b[A\n",
            "Iteration:  27% 98/363 [00:12<00:33,  7.82it/s]\u001b[A\n",
            "Iteration:  27% 99/363 [00:12<00:33,  7.87it/s]\u001b[A\n",
            "Iteration:  28% 100/363 [00:12<00:33,  7.82it/s]\u001b[A\n",
            "Iteration:  28% 101/363 [00:12<00:33,  7.77it/s]\u001b[A\n",
            "Iteration:  28% 102/363 [00:12<00:33,  7.83it/s]\u001b[A\n",
            "Iteration:  28% 103/363 [00:13<00:33,  7.86it/s]\u001b[A\n",
            "Iteration:  29% 104/363 [00:13<00:33,  7.82it/s]\u001b[A\n",
            "Iteration:  29% 105/363 [00:13<00:33,  7.73it/s]\u001b[A\n",
            "Iteration:  29% 106/363 [00:13<00:33,  7.78it/s]\u001b[A\n",
            "Iteration:  29% 107/363 [00:13<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  30% 108/363 [00:13<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  30% 109/363 [00:13<00:32,  7.88it/s]\u001b[A\n",
            "Iteration:  30% 110/363 [00:14<00:31,  7.91it/s]\u001b[A\n",
            "Iteration:  31% 111/363 [00:14<00:31,  7.90it/s]\u001b[A\n",
            "Iteration:  31% 112/363 [00:14<00:32,  7.83it/s]\u001b[A\n",
            "Iteration:  31% 113/363 [00:14<00:32,  7.80it/s]\u001b[A\n",
            "Iteration:  31% 114/363 [00:14<00:32,  7.76it/s]\u001b[A\n",
            "Iteration:  32% 115/363 [00:14<00:31,  7.76it/s]\u001b[A\n",
            "Iteration:  32% 116/363 [00:14<00:31,  7.79it/s]\u001b[A\n",
            "Iteration:  32% 117/363 [00:14<00:31,  7.86it/s]\u001b[A\n",
            "Iteration:  33% 118/363 [00:15<00:31,  7.88it/s]\u001b[A\n",
            "Iteration:  33% 119/363 [00:15<00:31,  7.82it/s]\u001b[A\n",
            "Iteration:  33% 120/363 [00:15<00:31,  7.83it/s]\u001b[A\n",
            "Iteration:  33% 121/363 [00:15<00:30,  7.83it/s]\u001b[A\n",
            "Iteration:  34% 122/363 [00:15<00:30,  7.86it/s]\u001b[A\n",
            "Iteration:  34% 123/363 [00:15<00:30,  7.82it/s]\u001b[A\n",
            "Iteration:  34% 124/363 [00:15<00:30,  7.86it/s]\u001b[A\n",
            "Iteration:  34% 125/363 [00:15<00:30,  7.91it/s]\u001b[A\n",
            "Iteration:  35% 126/363 [00:16<00:29,  7.92it/s]\u001b[A\n",
            "Iteration:  35% 127/363 [00:16<00:29,  7.87it/s]\u001b[A\n",
            "Iteration:  35% 128/363 [00:16<00:29,  7.88it/s]\u001b[A\n",
            "Iteration:  36% 129/363 [00:16<00:29,  7.88it/s]\u001b[A\n",
            "Iteration:  36% 130/363 [00:16<00:29,  7.85it/s]\u001b[A\n",
            "Iteration:  36% 131/363 [00:16<00:29,  7.83it/s]\u001b[A\n",
            "Iteration:  36% 132/363 [00:16<00:29,  7.87it/s]\u001b[A\n",
            "Iteration:  37% 133/363 [00:16<00:29,  7.90it/s]\u001b[A\n",
            "Iteration:  37% 134/363 [00:17<00:28,  7.90it/s]\u001b[A\n",
            "Iteration:  37% 135/363 [00:17<00:29,  7.83it/s]\u001b[A\n",
            "Iteration:  37% 136/363 [00:17<00:28,  7.85it/s]\u001b[A{\"loss\": 0.4791931744068861, \"learning_rate\": 1.0817263544536271e-05, \"epoch\": 1.3774104683195592, \"step\": 500}\n",
            "05/16/2020 05:20:18 - INFO - transformers.trainer -   Saving model checkpoint to sakamoto_bert/checkpoint-500\n",
            "05/16/2020 05:20:18 - INFO - transformers.configuration_utils -   Configuration saved in sakamoto_bert/checkpoint-500/config.json\n",
            "05/16/2020 05:20:19 - INFO - transformers.modeling_utils -   Model weights saved in sakamoto_bert/checkpoint-500/pytorch_model.bin\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
            "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
            "05/16/2020 05:20:22 - INFO - transformers.trainer -   Saving optimizer and scheduler states to sakamoto_bert/checkpoint-500\n",
            "\n",
            "Iteration:  38% 137/363 [00:22<05:44,  1.52s/it]\u001b[A\n",
            "Iteration:  38% 138/363 [00:22<04:09,  1.11s/it]\u001b[A\n",
            "Iteration:  38% 139/363 [00:22<03:03,  1.22it/s]\u001b[A\n",
            "Iteration:  39% 140/363 [00:22<02:16,  1.63it/s]\u001b[A\n",
            "Iteration:  39% 141/363 [00:22<01:43,  2.14it/s]\u001b[A\n",
            "Iteration:  39% 142/363 [00:22<01:20,  2.73it/s]\u001b[A\n",
            "Iteration:  39% 143/363 [00:22<01:04,  3.40it/s]\u001b[A\n",
            "Iteration:  40% 144/363 [00:23<00:53,  4.10it/s]\u001b[A\n",
            "Iteration:  40% 145/363 [00:23<00:45,  4.77it/s]\u001b[A\n",
            "Iteration:  40% 146/363 [00:23<00:40,  5.41it/s]\u001b[A\n",
            "Iteration:  40% 147/363 [00:23<00:36,  5.90it/s]\u001b[A\n",
            "Iteration:  41% 148/363 [00:23<00:34,  6.32it/s]\u001b[A\n",
            "Iteration:  41% 149/363 [00:23<00:31,  6.70it/s]\u001b[A\n",
            "Iteration:  41% 150/363 [00:23<00:30,  7.02it/s]\u001b[A\n",
            "Iteration:  42% 151/363 [00:23<00:29,  7.22it/s]\u001b[A\n",
            "Iteration:  42% 152/363 [00:24<00:28,  7.36it/s]\u001b[A\n",
            "Iteration:  42% 153/363 [00:24<00:27,  7.52it/s]\u001b[A\n",
            "Iteration:  42% 154/363 [00:24<00:27,  7.63it/s]\u001b[A\n",
            "Iteration:  43% 155/363 [00:24<00:27,  7.57it/s]\u001b[A\n",
            "Iteration:  43% 156/363 [00:24<00:27,  7.63it/s]\u001b[A\n",
            "Iteration:  43% 157/363 [00:24<00:26,  7.74it/s]\u001b[A\n",
            "Iteration:  44% 158/363 [00:24<00:26,  7.81it/s]\u001b[A\n",
            "Iteration:  44% 159/363 [00:24<00:26,  7.81it/s]\u001b[A\n",
            "Iteration:  44% 160/363 [00:25<00:25,  7.86it/s]\u001b[A\n",
            "Iteration:  44% 161/363 [00:25<00:25,  7.90it/s]\u001b[A\n",
            "Iteration:  45% 162/363 [00:25<00:26,  7.71it/s]\u001b[A\n",
            "Iteration:  45% 163/363 [00:25<00:25,  7.73it/s]\u001b[A\n",
            "Iteration:  45% 164/363 [00:25<00:25,  7.80it/s]\u001b[A\n",
            "Iteration:  45% 165/363 [00:25<00:25,  7.83it/s]\u001b[A\n",
            "Iteration:  46% 166/363 [00:25<00:25,  7.84it/s]\u001b[A\n",
            "Iteration:  46% 167/363 [00:25<00:25,  7.82it/s]\u001b[A\n",
            "Iteration:  46% 168/363 [00:26<00:24,  7.87it/s]\u001b[A\n",
            "Iteration:  47% 169/363 [00:26<00:24,  7.89it/s]\u001b[A\n",
            "Iteration:  47% 170/363 [00:26<00:24,  7.89it/s]\u001b[A\n",
            "Iteration:  47% 171/363 [00:26<00:24,  7.82it/s]\u001b[A\n",
            "Iteration:  47% 172/363 [00:26<00:24,  7.87it/s]\u001b[A\n",
            "Iteration:  48% 173/363 [00:26<00:24,  7.90it/s]\u001b[A\n",
            "Iteration:  48% 174/363 [00:26<00:24,  7.86it/s]\u001b[A\n",
            "Iteration:  48% 175/363 [00:26<00:23,  7.92it/s]\u001b[A\n",
            "Iteration:  48% 176/363 [00:27<00:23,  7.92it/s]\u001b[A\n",
            "Iteration:  49% 177/363 [00:27<00:23,  7.94it/s]\u001b[A\n",
            "Iteration:  49% 178/363 [00:27<00:23,  7.84it/s]\u001b[A\n",
            "Iteration:  49% 179/363 [00:27<00:23,  7.71it/s]\u001b[A\n",
            "Iteration:  50% 180/363 [00:27<00:23,  7.79it/s]\u001b[A\n",
            "Iteration:  50% 181/363 [00:27<00:23,  7.82it/s]\u001b[A\n",
            "Iteration:  50% 182/363 [00:27<00:22,  7.89it/s]\u001b[A\n",
            "Iteration:  50% 183/363 [00:28<00:22,  7.94it/s]\u001b[A\n",
            "Iteration:  51% 184/363 [00:28<00:22,  7.94it/s]\u001b[A\n",
            "Iteration:  51% 185/363 [00:28<00:22,  7.91it/s]\u001b[A\n",
            "Iteration:  51% 186/363 [00:28<00:22,  7.93it/s]\u001b[A\n",
            "Iteration:  52% 187/363 [00:28<00:22,  7.83it/s]\u001b[A\n",
            "Iteration:  52% 188/363 [00:28<00:22,  7.88it/s]\u001b[A\n",
            "Iteration:  52% 189/363 [00:28<00:22,  7.69it/s]\u001b[A\n",
            "Iteration:  52% 190/363 [00:28<00:22,  7.77it/s]\u001b[A\n",
            "Iteration:  53% 191/363 [00:29<00:21,  7.85it/s]\u001b[A\n",
            "Iteration:  53% 192/363 [00:29<00:21,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 193/363 [00:29<00:21,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 194/363 [00:29<00:21,  7.87it/s]\u001b[A\n",
            "Iteration:  54% 195/363 [00:29<00:21,  7.79it/s]\u001b[A\n",
            "Iteration:  54% 196/363 [00:29<00:21,  7.83it/s]\u001b[A\n",
            "Iteration:  54% 197/363 [00:29<00:21,  7.80it/s]\u001b[A\n",
            "Iteration:  55% 198/363 [00:29<00:21,  7.79it/s]\u001b[A\n",
            "Iteration:  55% 199/363 [00:30<00:20,  7.86it/s]\u001b[A\n",
            "Iteration:  55% 200/363 [00:30<00:20,  7.86it/s]\u001b[A\n",
            "Iteration:  55% 201/363 [00:30<00:20,  7.88it/s]\u001b[A\n",
            "Iteration:  56% 202/363 [00:30<00:20,  7.91it/s]\u001b[A\n",
            "Iteration:  56% 203/363 [00:30<00:20,  7.81it/s]\u001b[A\n",
            "Iteration:  56% 204/363 [00:30<00:20,  7.81it/s]\u001b[A\n",
            "Iteration:  56% 205/363 [00:30<00:20,  7.85it/s]\u001b[A\n",
            "Iteration:  57% 206/363 [00:30<00:19,  7.90it/s]\u001b[A\n",
            "Iteration:  57% 207/363 [00:31<00:19,  7.81it/s]\u001b[A\n",
            "Iteration:  57% 208/363 [00:31<00:19,  7.82it/s]\u001b[A\n",
            "Iteration:  58% 209/363 [00:31<00:19,  7.75it/s]\u001b[A\n",
            "Iteration:  58% 210/363 [00:31<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  58% 211/363 [00:31<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  58% 212/363 [00:31<00:19,  7.82it/s]\u001b[A\n",
            "Iteration:  59% 213/363 [00:31<00:19,  7.87it/s]\u001b[A\n",
            "Iteration:  59% 214/363 [00:31<00:19,  7.83it/s]\u001b[A\n",
            "Iteration:  59% 215/363 [00:32<00:18,  7.86it/s]\u001b[A\n",
            "Iteration:  60% 216/363 [00:32<00:18,  7.90it/s]\u001b[A\n",
            "Iteration:  60% 217/363 [00:32<00:18,  7.92it/s]\u001b[A\n",
            "Iteration:  60% 218/363 [00:32<00:18,  7.92it/s]\u001b[A\n",
            "Iteration:  60% 219/363 [00:32<00:18,  7.77it/s]\u001b[A\n",
            "Iteration:  61% 220/363 [00:32<00:18,  7.87it/s]\u001b[A\n",
            "Iteration:  61% 221/363 [00:32<00:17,  7.95it/s]\u001b[A\n",
            "Iteration:  61% 222/363 [00:32<00:17,  7.91it/s]\u001b[A\n",
            "Iteration:  61% 223/363 [00:33<00:17,  7.87it/s]\u001b[A\n",
            "Iteration:  62% 224/363 [00:33<00:17,  7.91it/s]\u001b[A\n",
            "Iteration:  62% 225/363 [00:33<00:17,  7.89it/s]\u001b[A\n",
            "Iteration:  62% 226/363 [00:33<00:17,  7.91it/s]\u001b[A\n",
            "Iteration:  63% 227/363 [00:33<00:17,  7.79it/s]\u001b[A\n",
            "Iteration:  63% 228/363 [00:33<00:17,  7.87it/s]\u001b[A\n",
            "Iteration:  63% 229/363 [00:33<00:16,  7.91it/s]\u001b[A\n",
            "Iteration:  63% 230/363 [00:34<00:16,  7.83it/s]\u001b[A\n",
            "Iteration:  64% 231/363 [00:34<00:16,  7.85it/s]\u001b[A\n",
            "Iteration:  64% 232/363 [00:34<00:16,  7.88it/s]\u001b[A\n",
            "Iteration:  64% 233/363 [00:34<00:16,  7.87it/s]\u001b[A\n",
            "Iteration:  64% 234/363 [00:34<00:16,  7.90it/s]\u001b[A\n",
            "Iteration:  65% 235/363 [00:34<00:16,  7.78it/s]\u001b[A\n",
            "Iteration:  65% 236/363 [00:34<00:16,  7.85it/s]\u001b[A\n",
            "Iteration:  65% 237/363 [00:34<00:15,  7.89it/s]\u001b[A\n",
            "Iteration:  66% 238/363 [00:35<00:15,  7.82it/s]\u001b[A\n",
            "Iteration:  66% 239/363 [00:35<00:15,  7.79it/s]\u001b[A\n",
            "Iteration:  66% 240/363 [00:35<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  66% 241/363 [00:35<00:15,  7.86it/s]\u001b[A\n",
            "Iteration:  67% 242/363 [00:35<00:15,  7.89it/s]\u001b[A\n",
            "Iteration:  67% 243/363 [00:35<00:15,  7.69it/s]\u001b[A\n",
            "Iteration:  67% 244/363 [00:35<00:15,  7.78it/s]\u001b[A\n",
            "Iteration:  67% 245/363 [00:35<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  68% 246/363 [00:36<00:15,  7.79it/s]\u001b[A\n",
            "Iteration:  68% 247/363 [00:36<00:14,  7.83it/s]\u001b[A\n",
            "Iteration:  68% 248/363 [00:36<00:14,  7.87it/s]\u001b[A\n",
            "Iteration:  69% 249/363 [00:36<00:14,  7.89it/s]\u001b[A\n",
            "Iteration:  69% 250/363 [00:36<00:14,  7.89it/s]\u001b[A\n",
            "Iteration:  69% 251/363 [00:36<00:14,  7.82it/s]\u001b[A\n",
            "Iteration:  69% 252/363 [00:36<00:14,  7.87it/s]\u001b[A\n",
            "Iteration:  70% 253/363 [00:36<00:14,  7.78it/s]\u001b[A\n",
            "Iteration:  70% 254/363 [00:37<00:13,  7.83it/s]\u001b[A\n",
            "Iteration:  70% 255/363 [00:37<00:13,  7.89it/s]\u001b[A\n",
            "Iteration:  71% 256/363 [00:37<00:13,  7.90it/s]\u001b[A\n",
            "Iteration:  71% 257/363 [00:37<00:13,  7.89it/s]\u001b[A\n",
            "Iteration:  71% 258/363 [00:37<00:13,  7.91it/s]\u001b[A\n",
            "Iteration:  71% 259/363 [00:37<00:13,  7.72it/s]\u001b[A\n",
            "Iteration:  72% 260/363 [00:37<00:13,  7.78it/s]\u001b[A\n",
            "Iteration:  72% 261/363 [00:37<00:13,  7.79it/s]\u001b[A\n",
            "Iteration:  72% 262/363 [00:38<00:12,  7.86it/s]\u001b[A\n",
            "Iteration:  72% 263/363 [00:38<00:12,  7.90it/s]\u001b[A\n",
            "Iteration:  73% 264/363 [00:38<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  73% 265/363 [00:38<00:12,  7.89it/s]\u001b[A\n",
            "Iteration:  73% 266/363 [00:38<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  74% 267/363 [00:38<00:12,  7.84it/s]\u001b[A\n",
            "Iteration:  74% 268/363 [00:38<00:12,  7.81it/s]\u001b[A\n",
            "Iteration:  74% 269/363 [00:38<00:12,  7.82it/s]\u001b[A\n",
            "Iteration:  74% 270/363 [00:39<00:11,  7.87it/s]\u001b[A\n",
            "Iteration:  75% 271/363 [00:39<00:11,  7.90it/s]\u001b[A\n",
            "Iteration:  75% 272/363 [00:39<00:11,  7.88it/s]\u001b[A\n",
            "Iteration:  75% 273/363 [00:39<00:11,  7.90it/s]\u001b[A\n",
            "Iteration:  75% 274/363 [00:39<00:11,  7.87it/s]\u001b[A\n",
            "Iteration:  76% 275/363 [00:39<00:11,  7.78it/s]\u001b[A\n",
            "Iteration:  76% 276/363 [00:39<00:11,  7.84it/s]\u001b[A\n",
            "Iteration:  76% 277/363 [00:39<00:10,  7.88it/s]\u001b[A\n",
            "Iteration:  77% 278/363 [00:40<00:10,  7.91it/s]\u001b[A\n",
            "Iteration:  77% 279/363 [00:40<00:10,  7.93it/s]\u001b[A\n",
            "Iteration:  77% 280/363 [00:40<00:10,  7.90it/s]\u001b[A\n",
            "Iteration:  77% 281/363 [00:40<00:10,  7.92it/s]\u001b[A\n",
            "Iteration:  78% 282/363 [00:40<00:10,  7.86it/s]\u001b[A\n",
            "Iteration:  78% 283/363 [00:40<00:10,  7.79it/s]\u001b[A\n",
            "Iteration:  78% 284/363 [00:40<00:10,  7.85it/s]\u001b[A\n",
            "Iteration:  79% 285/363 [00:41<00:09,  7.91it/s]\u001b[A\n",
            "Iteration:  79% 286/363 [00:41<00:09,  7.93it/s]\u001b[A\n",
            "Iteration:  79% 287/363 [00:41<00:09,  7.84it/s]\u001b[A\n",
            "Iteration:  79% 288/363 [00:41<00:09,  7.84it/s]\u001b[A\n",
            "Iteration:  80% 289/363 [00:41<00:09,  7.88it/s]\u001b[A\n",
            "Iteration:  80% 290/363 [00:41<00:09,  7.90it/s]\u001b[A\n",
            "Iteration:  80% 291/363 [00:41<00:09,  7.76it/s]\u001b[A\n",
            "Iteration:  80% 292/363 [00:41<00:09,  7.79it/s]\u001b[A\n",
            "Iteration:  81% 293/363 [00:42<00:08,  7.84it/s]\u001b[A\n",
            "Iteration:  81% 294/363 [00:42<00:08,  7.79it/s]\u001b[A\n",
            "Iteration:  81% 295/363 [00:42<00:08,  7.82it/s]\u001b[A\n",
            "Iteration:  82% 296/363 [00:42<00:08,  7.87it/s]\u001b[A\n",
            "Iteration:  82% 297/363 [00:42<00:08,  7.82it/s]\u001b[A\n",
            "Iteration:  82% 298/363 [00:42<00:08,  7.85it/s]\u001b[A\n",
            "Iteration:  82% 299/363 [00:42<00:08,  7.74it/s]\u001b[A\n",
            "Iteration:  83% 300/363 [00:42<00:08,  7.76it/s]\u001b[A\n",
            "Iteration:  83% 301/363 [00:43<00:08,  7.69it/s]\u001b[A\n",
            "Iteration:  83% 302/363 [00:43<00:07,  7.75it/s]\u001b[A\n",
            "Iteration:  83% 303/363 [00:43<00:07,  7.79it/s]\u001b[A\n",
            "Iteration:  84% 304/363 [00:43<00:07,  7.85it/s]\u001b[A\n",
            "Iteration:  84% 305/363 [00:43<00:07,  7.81it/s]\u001b[A\n",
            "Iteration:  84% 306/363 [00:43<00:07,  7.84it/s]\u001b[A\n",
            "Iteration:  85% 307/363 [00:43<00:07,  7.73it/s]\u001b[A\n",
            "Iteration:  85% 308/363 [00:43<00:07,  7.78it/s]\u001b[A\n",
            "Iteration:  85% 309/363 [00:44<00:06,  7.83it/s]\u001b[A\n",
            "Iteration:  85% 310/363 [00:44<00:06,  7.84it/s]\u001b[A\n",
            "Iteration:  86% 311/363 [00:44<00:06,  7.84it/s]\u001b[A\n",
            "Iteration:  86% 312/363 [00:44<00:06,  7.82it/s]\u001b[A\n",
            "Iteration:  86% 313/363 [00:44<00:06,  7.85it/s]\u001b[A\n",
            "Iteration:  87% 314/363 [00:44<00:06,  7.84it/s]\u001b[A\n",
            "Iteration:  87% 315/363 [00:44<00:06,  7.75it/s]\u001b[A\n",
            "Iteration:  87% 316/363 [00:44<00:06,  7.81it/s]\u001b[A\n",
            "Iteration:  87% 317/363 [00:45<00:05,  7.82it/s]\u001b[A\n",
            "Iteration:  88% 318/363 [00:45<00:05,  7.80it/s]\u001b[A\n",
            "Iteration:  88% 319/363 [00:45<00:05,  7.82it/s]\u001b[A\n",
            "Iteration:  88% 320/363 [00:45<00:05,  7.85it/s]\u001b[A\n",
            "Iteration:  88% 321/363 [00:45<00:05,  7.86it/s]\u001b[A\n",
            "Iteration:  89% 322/363 [00:45<00:05,  7.82it/s]\u001b[A\n",
            "Iteration:  89% 323/363 [00:45<00:05,  7.78it/s]\u001b[A\n",
            "Iteration:  89% 324/363 [00:46<00:05,  7.75it/s]\u001b[A\n",
            "Iteration:  90% 325/363 [00:46<00:04,  7.81it/s]\u001b[A\n",
            "Iteration:  90% 326/363 [00:46<00:04,  7.87it/s]\u001b[A\n",
            "Iteration:  90% 327/363 [00:46<00:04,  7.89it/s]\u001b[A\n",
            "Iteration:  90% 328/363 [00:46<00:04,  7.93it/s]\u001b[A\n",
            "Iteration:  91% 329/363 [00:46<00:04,  7.89it/s]\u001b[A\n",
            "Iteration:  91% 330/363 [00:46<00:04,  7.94it/s]\u001b[A\n",
            "Iteration:  91% 331/363 [00:46<00:04,  7.84it/s]\u001b[A\n",
            "Iteration:  91% 332/363 [00:47<00:03,  7.90it/s]\u001b[A\n",
            "Iteration:  92% 333/363 [00:47<00:03,  7.88it/s]\u001b[A\n",
            "Iteration:  92% 334/363 [00:47<00:03,  7.65it/s]\u001b[A\n",
            "Iteration:  92% 335/363 [00:47<00:03,  7.75it/s]\u001b[A\n",
            "Iteration:  93% 336/363 [00:47<00:03,  7.82it/s]\u001b[A\n",
            "Iteration:  93% 337/363 [00:47<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  93% 338/363 [00:47<00:03,  7.84it/s]\u001b[A\n",
            "Iteration:  93% 339/363 [00:47<00:03,  7.82it/s]\u001b[A\n",
            "Iteration:  94% 340/363 [00:48<00:02,  7.86it/s]\u001b[A\n",
            "Iteration:  94% 341/363 [00:48<00:02,  7.73it/s]\u001b[A\n",
            "Iteration:  94% 342/363 [00:48<00:02,  7.81it/s]\u001b[A\n",
            "Iteration:  94% 343/363 [00:48<00:02,  7.84it/s]\u001b[A\n",
            "Iteration:  95% 344/363 [00:48<00:02,  7.88it/s]\u001b[A\n",
            "Iteration:  95% 345/363 [00:48<00:02,  7.83it/s]\u001b[A\n",
            "Iteration:  95% 346/363 [00:48<00:02,  7.88it/s]\u001b[A\n",
            "Iteration:  96% 347/363 [00:48<00:02,  7.81it/s]\u001b[A\n",
            "Iteration:  96% 348/363 [00:49<00:01,  7.72it/s]\u001b[A\n",
            "Iteration:  96% 349/363 [00:49<00:01,  7.68it/s]\u001b[A\n",
            "Iteration:  96% 350/363 [00:49<00:01,  7.75it/s]\u001b[A\n",
            "Iteration:  97% 351/363 [00:49<00:01,  7.82it/s]\u001b[A\n",
            "Iteration:  97% 352/363 [00:49<00:01,  7.87it/s]\u001b[A\n",
            "Iteration:  97% 353/363 [00:49<00:01,  7.89it/s]\u001b[A\n",
            "Iteration:  98% 354/363 [00:49<00:01,  7.92it/s]\u001b[A\n",
            "Iteration:  98% 355/363 [00:49<00:01,  7.87it/s]\u001b[A\n",
            "Iteration:  98% 356/363 [00:50<00:00,  7.89it/s]\u001b[A\n",
            "Iteration:  98% 357/363 [00:50<00:00,  7.80it/s]\u001b[A\n",
            "Iteration:  99% 358/363 [00:50<00:00,  7.84it/s]\u001b[A\n",
            "Iteration:  99% 359/363 [00:50<00:00,  7.81it/s]\u001b[A\n",
            "Iteration:  99% 360/363 [00:50<00:00,  7.86it/s]\u001b[A\n",
            "Iteration:  99% 361/363 [00:50<00:00,  7.89it/s]\u001b[A\n",
            "Iteration: 100% 362/363 [00:50<00:00,  7.89it/s]\u001b[A\n",
            "Iteration: 100% 363/363 [00:50<00:00,  7.12it/s]\n",
            "Epoch:  67% 2/3 [01:37<00:47, 47.98s/it]\n",
            "Iteration:   0% 0/363 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/363 [00:00<00:47,  7.55it/s]\u001b[A\n",
            "Iteration:   1% 2/363 [00:00<00:48,  7.48it/s]\u001b[A\n",
            "Iteration:   1% 3/363 [00:00<00:47,  7.62it/s]\u001b[A\n",
            "Iteration:   1% 4/363 [00:00<00:46,  7.68it/s]\u001b[A\n",
            "Iteration:   1% 5/363 [00:00<00:46,  7.77it/s]\u001b[A\n",
            "Iteration:   2% 6/363 [00:00<00:45,  7.76it/s]\u001b[A\n",
            "Iteration:   2% 7/363 [00:00<00:45,  7.77it/s]\u001b[A\n",
            "Iteration:   2% 8/363 [00:01<00:46,  7.70it/s]\u001b[A\n",
            "Iteration:   2% 9/363 [00:01<00:45,  7.73it/s]\u001b[A\n",
            "Iteration:   3% 10/363 [00:01<00:46,  7.63it/s]\u001b[A\n",
            "Iteration:   3% 11/363 [00:01<00:45,  7.66it/s]\u001b[A\n",
            "Iteration:   3% 12/363 [00:01<00:45,  7.70it/s]\u001b[A\n",
            "Iteration:   4% 13/363 [00:01<00:45,  7.72it/s]\u001b[A\n",
            "Iteration:   4% 14/363 [00:01<00:45,  7.70it/s]\u001b[A\n",
            "Iteration:   4% 15/363 [00:01<00:45,  7.73it/s]\u001b[A\n",
            "Iteration:   4% 16/363 [00:02<00:44,  7.74it/s]\u001b[A\n",
            "Iteration:   5% 17/363 [00:02<00:44,  7.76it/s]\u001b[A\n",
            "Iteration:   5% 18/363 [00:02<00:44,  7.78it/s]\u001b[A\n",
            "Iteration:   5% 19/363 [00:02<00:43,  7.83it/s]\u001b[A\n",
            "Iteration:   6% 20/363 [00:02<00:43,  7.87it/s]\u001b[A\n",
            "Iteration:   6% 21/363 [00:02<00:43,  7.89it/s]\u001b[A\n",
            "Iteration:   6% 22/363 [00:02<00:43,  7.87it/s]\u001b[A\n",
            "Iteration:   6% 23/363 [00:02<00:43,  7.90it/s]\u001b[A\n",
            "Iteration:   7% 24/363 [00:03<00:42,  7.93it/s]\u001b[A\n",
            "Iteration:   7% 25/363 [00:03<00:42,  7.94it/s]\u001b[A\n",
            "Iteration:   7% 26/363 [00:03<00:42,  7.91it/s]\u001b[A\n",
            "Iteration:   7% 27/363 [00:03<00:42,  7.92it/s]\u001b[A\n",
            "Iteration:   8% 28/363 [00:03<00:42,  7.94it/s]\u001b[A\n",
            "Iteration:   8% 29/363 [00:03<00:42,  7.95it/s]\u001b[A\n",
            "Iteration:   8% 30/363 [00:03<00:42,  7.91it/s]\u001b[A\n",
            "Iteration:   9% 31/363 [00:03<00:42,  7.90it/s]\u001b[A\n",
            "Iteration:   9% 32/363 [00:04<00:41,  7.89it/s]\u001b[A\n",
            "Iteration:   9% 33/363 [00:04<00:42,  7.76it/s]\u001b[A\n",
            "Iteration:   9% 34/363 [00:04<00:43,  7.64it/s]\u001b[A\n",
            "Iteration:  10% 35/363 [00:04<00:42,  7.73it/s]\u001b[A\n",
            "Iteration:  10% 36/363 [00:04<00:41,  7.82it/s]\u001b[A\n",
            "Iteration:  10% 37/363 [00:04<00:41,  7.86it/s]\u001b[A\n",
            "Iteration:  10% 38/363 [00:04<00:41,  7.88it/s]\u001b[A\n",
            "Iteration:  11% 39/363 [00:04<00:40,  7.91it/s]\u001b[A\n",
            "Iteration:  11% 40/363 [00:05<00:41,  7.86it/s]\u001b[A\n",
            "Iteration:  11% 41/363 [00:05<00:41,  7.77it/s]\u001b[A\n",
            "Iteration:  12% 42/363 [00:05<00:40,  7.85it/s]\u001b[A\n",
            "Iteration:  12% 43/363 [00:05<00:40,  7.84it/s]\u001b[A\n",
            "Iteration:  12% 44/363 [00:05<00:40,  7.91it/s]\u001b[A\n",
            "Iteration:  12% 45/363 [00:05<00:40,  7.93it/s]\u001b[A\n",
            "Iteration:  13% 46/363 [00:05<00:40,  7.87it/s]\u001b[A\n",
            "Iteration:  13% 47/363 [00:06<00:39,  7.94it/s]\u001b[A\n",
            "Iteration:  13% 48/363 [00:06<00:39,  7.94it/s]\u001b[A\n",
            "Iteration:  13% 49/363 [00:06<00:40,  7.68it/s]\u001b[A\n",
            "Iteration:  14% 50/363 [00:06<00:40,  7.74it/s]\u001b[A\n",
            "Iteration:  14% 51/363 [00:06<00:40,  7.76it/s]\u001b[A\n",
            "Iteration:  14% 52/363 [00:06<00:39,  7.86it/s]\u001b[A\n",
            "Iteration:  15% 53/363 [00:06<00:39,  7.88it/s]\u001b[A\n",
            "Iteration:  15% 54/363 [00:06<00:38,  7.96it/s]\u001b[A\n",
            "Iteration:  15% 55/363 [00:07<00:38,  7.94it/s]\u001b[A\n",
            "Iteration:  15% 56/363 [00:07<00:38,  7.94it/s]\u001b[A\n",
            "Iteration:  16% 57/363 [00:07<00:38,  7.91it/s]\u001b[A\n",
            "Iteration:  16% 58/363 [00:07<00:38,  7.89it/s]\u001b[A\n",
            "Iteration:  16% 59/363 [00:07<00:38,  7.92it/s]\u001b[A\n",
            "Iteration:  17% 60/363 [00:07<00:38,  7.91it/s]\u001b[A\n",
            "Iteration:  17% 61/363 [00:07<00:38,  7.94it/s]\u001b[A\n",
            "Iteration:  17% 62/363 [00:07<00:38,  7.88it/s]\u001b[A\n",
            "Iteration:  17% 63/363 [00:08<00:37,  7.91it/s]\u001b[A\n",
            "Iteration:  18% 64/363 [00:08<00:38,  7.74it/s]\u001b[A\n",
            "Iteration:  18% 65/363 [00:08<00:38,  7.81it/s]\u001b[A\n",
            "Iteration:  18% 66/363 [00:08<00:37,  7.90it/s]\u001b[A\n",
            "Iteration:  18% 67/363 [00:08<00:37,  7.90it/s]\u001b[A\n",
            "Iteration:  19% 68/363 [00:08<00:37,  7.92it/s]\u001b[A\n",
            "Iteration:  19% 69/363 [00:08<00:37,  7.94it/s]\u001b[A\n",
            "Iteration:  19% 70/363 [00:08<00:36,  7.99it/s]\u001b[A\n",
            "Iteration:  20% 71/363 [00:09<00:36,  8.01it/s]\u001b[A\n",
            "Iteration:  20% 72/363 [00:09<00:36,  7.91it/s]\u001b[A\n",
            "Iteration:  20% 73/363 [00:09<00:36,  7.92it/s]\u001b[A\n",
            "Iteration:  20% 74/363 [00:09<00:36,  7.92it/s]\u001b[A\n",
            "Iteration:  21% 75/363 [00:09<00:36,  7.94it/s]\u001b[A\n",
            "Iteration:  21% 76/363 [00:09<00:36,  7.95it/s]\u001b[A\n",
            "Iteration:  21% 77/363 [00:09<00:36,  7.94it/s]\u001b[A\n",
            "Iteration:  21% 78/363 [00:09<00:35,  7.94it/s]\u001b[A\n",
            "Iteration:  22% 79/363 [00:10<00:35,  7.96it/s]\u001b[A\n",
            "Iteration:  22% 80/363 [00:10<00:35,  7.87it/s]\u001b[A\n",
            "Iteration:  22% 81/363 [00:10<00:36,  7.69it/s]\u001b[A\n",
            "Iteration:  23% 82/363 [00:10<00:36,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 83/363 [00:10<00:35,  7.87it/s]\u001b[A\n",
            "Iteration:  23% 84/363 [00:10<00:35,  7.90it/s]\u001b[A\n",
            "Iteration:  23% 85/363 [00:10<00:35,  7.88it/s]\u001b[A\n",
            "Iteration:  24% 86/363 [00:10<00:34,  7.95it/s]\u001b[A\n",
            "Iteration:  24% 87/363 [00:11<00:34,  7.97it/s]\u001b[A\n",
            "Iteration:  24% 88/363 [00:11<00:35,  7.79it/s]\u001b[A\n",
            "Iteration:  25% 89/363 [00:11<00:34,  7.87it/s]\u001b[A\n",
            "Iteration:  25% 90/363 [00:11<00:34,  7.90it/s]\u001b[A\n",
            "Iteration:  25% 91/363 [00:11<00:34,  7.92it/s]\u001b[A\n",
            "Iteration:  25% 92/363 [00:11<00:34,  7.90it/s]\u001b[A\n",
            "Iteration:  26% 93/363 [00:11<00:34,  7.93it/s]\u001b[A\n",
            "Iteration:  26% 94/363 [00:11<00:33,  7.93it/s]\u001b[A\n",
            "Iteration:  26% 95/363 [00:12<00:33,  7.95it/s]\u001b[A\n",
            "Iteration:  26% 96/363 [00:12<00:34,  7.68it/s]\u001b[A\n",
            "Iteration:  27% 97/363 [00:12<00:34,  7.75it/s]\u001b[A\n",
            "Iteration:  27% 98/363 [00:12<00:33,  7.81it/s]\u001b[A\n",
            "Iteration:  27% 99/363 [00:12<00:33,  7.86it/s]\u001b[A\n",
            "Iteration:  28% 100/363 [00:12<00:33,  7.86it/s]\u001b[A\n",
            "Iteration:  28% 101/363 [00:12<00:33,  7.94it/s]\u001b[A\n",
            "Iteration:  28% 102/363 [00:12<00:32,  7.95it/s]\u001b[A\n",
            "Iteration:  28% 103/363 [00:13<00:32,  7.96it/s]\u001b[A\n",
            "Iteration:  29% 104/363 [00:13<00:32,  7.89it/s]\u001b[A\n",
            "Iteration:  29% 105/363 [00:13<00:32,  7.89it/s]\u001b[A\n",
            "Iteration:  29% 106/363 [00:13<00:32,  7.91it/s]\u001b[A\n",
            "Iteration:  29% 107/363 [00:13<00:32,  7.90it/s]\u001b[A\n",
            "Iteration:  30% 108/363 [00:13<00:32,  7.84it/s]\u001b[A\n",
            "Iteration:  30% 109/363 [00:13<00:32,  7.91it/s]\u001b[A\n",
            "Iteration:  30% 110/363 [00:13<00:31,  7.91it/s]\u001b[A\n",
            "Iteration:  31% 111/363 [00:14<00:31,  7.91it/s]\u001b[A\n",
            "Iteration:  31% 112/363 [00:14<00:32,  7.83it/s]\u001b[A\n",
            "Iteration:  31% 113/363 [00:14<00:31,  7.89it/s]\u001b[A\n",
            "Iteration:  31% 114/363 [00:14<00:31,  7.91it/s]\u001b[A\n",
            "Iteration:  32% 115/363 [00:14<00:31,  7.89it/s]\u001b[A\n",
            "Iteration:  32% 116/363 [00:14<00:31,  7.94it/s]\u001b[A\n",
            "Iteration:  32% 117/363 [00:14<00:30,  7.98it/s]\u001b[A\n",
            "Iteration:  33% 118/363 [00:15<00:30,  7.93it/s]\u001b[A\n",
            "Iteration:  33% 119/363 [00:15<00:30,  7.91it/s]\u001b[A\n",
            "Iteration:  33% 120/363 [00:15<00:30,  7.95it/s]\u001b[A\n",
            "Iteration:  33% 121/363 [00:15<00:30,  7.98it/s]\u001b[A\n",
            "Iteration:  34% 122/363 [00:15<00:30,  7.92it/s]\u001b[A\n",
            "Iteration:  34% 123/363 [00:15<00:30,  7.96it/s]\u001b[A\n",
            "Iteration:  34% 124/363 [00:15<00:29,  7.99it/s]\u001b[A\n",
            "Iteration:  34% 125/363 [00:15<00:29,  7.96it/s]\u001b[A\n",
            "Iteration:  35% 126/363 [00:16<00:29,  7.95it/s]\u001b[A\n",
            "Iteration:  35% 127/363 [00:16<00:30,  7.83it/s]\u001b[A\n",
            "Iteration:  35% 128/363 [00:16<00:29,  7.87it/s]\u001b[A\n",
            "Iteration:  36% 129/363 [00:16<00:30,  7.72it/s]\u001b[A\n",
            "Iteration:  36% 130/363 [00:16<00:29,  7.79it/s]\u001b[A\n",
            "Iteration:  36% 131/363 [00:16<00:29,  7.85it/s]\u001b[A\n",
            "Iteration:  36% 132/363 [00:16<00:29,  7.89it/s]\u001b[A\n",
            "Iteration:  37% 133/363 [00:16<00:29,  7.90it/s]\u001b[A\n",
            "Iteration:  37% 134/363 [00:17<00:28,  7.96it/s]\u001b[A\n",
            "Iteration:  37% 135/363 [00:17<00:28,  7.99it/s]\u001b[A\n",
            "Iteration:  37% 136/363 [00:17<00:28,  7.99it/s]\u001b[A\n",
            "Iteration:  38% 137/363 [00:17<00:28,  7.93it/s]\u001b[A\n",
            "Iteration:  38% 138/363 [00:17<00:28,  7.91it/s]\u001b[A\n",
            "Iteration:  38% 139/363 [00:17<00:28,  7.82it/s]\u001b[A\n",
            "Iteration:  39% 140/363 [00:17<00:28,  7.91it/s]\u001b[A\n",
            "Iteration:  39% 141/363 [00:17<00:28,  7.91it/s]\u001b[A\n",
            "Iteration:  39% 142/363 [00:18<00:27,  7.93it/s]\u001b[A\n",
            "Iteration:  39% 143/363 [00:18<00:27,  7.97it/s]\u001b[A\n",
            "Iteration:  40% 144/363 [00:18<00:27,  7.98it/s]\u001b[A\n",
            "Iteration:  40% 145/363 [00:18<00:27,  7.87it/s]\u001b[A\n",
            "Iteration:  40% 146/363 [00:18<00:27,  7.90it/s]\u001b[A\n",
            "Iteration:  40% 147/363 [00:18<00:27,  7.92it/s]\u001b[A\n",
            "Iteration:  41% 148/363 [00:18<00:26,  7.97it/s]\u001b[A\n",
            "Iteration:  41% 149/363 [00:18<00:26,  7.99it/s]\u001b[A\n",
            "Iteration:  41% 150/363 [00:19<00:26,  8.03it/s]\u001b[A\n",
            "Iteration:  42% 151/363 [00:19<00:26,  7.92it/s]\u001b[A\n",
            "Iteration:  42% 152/363 [00:19<00:26,  7.92it/s]\u001b[A\n",
            "Iteration:  42% 153/363 [00:19<00:26,  7.88it/s]\u001b[A\n",
            "Iteration:  42% 154/363 [00:19<00:26,  7.94it/s]\u001b[A\n",
            "Iteration:  43% 155/363 [00:19<00:26,  7.95it/s]\u001b[A\n",
            "Iteration:  43% 156/363 [00:19<00:25,  7.97it/s]\u001b[A\n",
            "Iteration:  43% 157/363 [00:19<00:25,  7.96it/s]\u001b[A\n",
            "Iteration:  44% 158/363 [00:20<00:25,  7.93it/s]\u001b[A\n",
            "Iteration:  44% 159/363 [00:20<00:25,  7.93it/s]\u001b[A\n",
            "Iteration:  44% 160/363 [00:20<00:25,  7.97it/s]\u001b[A\n",
            "Iteration:  44% 161/363 [00:20<00:25,  7.97it/s]\u001b[A\n",
            "Iteration:  45% 162/363 [00:20<00:25,  7.93it/s]\u001b[A\n",
            "Iteration:  45% 163/363 [00:20<00:25,  7.96it/s]\u001b[A\n",
            "Iteration:  45% 164/363 [00:20<00:24,  7.98it/s]\u001b[A\n",
            "Iteration:  45% 165/363 [00:20<00:24,  7.96it/s]\u001b[A\n",
            "Iteration:  46% 166/363 [00:21<00:24,  7.92it/s]\u001b[A\n",
            "Iteration:  46% 167/363 [00:21<00:24,  7.94it/s]\u001b[A\n",
            "Iteration:  46% 168/363 [00:21<00:24,  7.93it/s]\u001b[A\n",
            "Iteration:  47% 169/363 [00:21<00:24,  7.97it/s]\u001b[A\n",
            "Iteration:  47% 170/363 [00:21<00:24,  7.96it/s]\u001b[A\n",
            "Iteration:  47% 171/363 [00:21<00:24,  7.96it/s]\u001b[A\n",
            "Iteration:  47% 172/363 [00:21<00:23,  8.01it/s]\u001b[A\n",
            "Iteration:  48% 173/363 [00:21<00:23,  8.04it/s]\u001b[A\n",
            "Iteration:  48% 174/363 [00:22<00:23,  7.97it/s]\u001b[A\n",
            "Iteration:  48% 175/363 [00:22<00:24,  7.83it/s]\u001b[A\n",
            "Iteration:  48% 176/363 [00:22<00:23,  7.85it/s]\u001b[A\n",
            "Iteration:  49% 177/363 [00:22<00:23,  7.92it/s]\u001b[A\n",
            "Iteration:  49% 178/363 [00:22<00:23,  7.93it/s]\u001b[A\n",
            "Iteration:  49% 179/363 [00:22<00:23,  7.96it/s]\u001b[A\n",
            "Iteration:  50% 180/363 [00:22<00:22,  7.97it/s]\u001b[A\n",
            "Iteration:  50% 181/363 [00:22<00:22,  8.00it/s]\u001b[A\n",
            "Iteration:  50% 182/363 [00:23<00:22,  7.97it/s]\u001b[A\n",
            "Iteration:  50% 183/363 [00:23<00:22,  7.86it/s]\u001b[A\n",
            "Iteration:  51% 184/363 [00:23<00:22,  7.82it/s]\u001b[A\n",
            "Iteration:  51% 185/363 [00:23<00:23,  7.62it/s]\u001b[A\n",
            "Iteration:  51% 186/363 [00:23<00:22,  7.75it/s]\u001b[A\n",
            "Iteration:  52% 187/363 [00:23<00:22,  7.85it/s]\u001b[A\n",
            "Iteration:  52% 188/363 [00:23<00:22,  7.88it/s]\u001b[A\n",
            "Iteration:  52% 189/363 [00:23<00:22,  7.85it/s]\u001b[A\n",
            "Iteration:  52% 190/363 [00:24<00:21,  7.92it/s]\u001b[A\n",
            "Iteration:  53% 191/363 [00:24<00:22,  7.76it/s]\u001b[A\n",
            "Iteration:  53% 192/363 [00:24<00:21,  7.79it/s]\u001b[A\n",
            "Iteration:  53% 193/363 [00:24<00:21,  7.79it/s]\u001b[A\n",
            "Iteration:  53% 194/363 [00:24<00:21,  7.82it/s]\u001b[A\n",
            "Iteration:  54% 195/363 [00:24<00:21,  7.85it/s]\u001b[A\n",
            "Iteration:  54% 196/363 [00:24<00:21,  7.89it/s]\u001b[A\n",
            "Iteration:  54% 197/363 [00:24<00:20,  7.91it/s]\u001b[A\n",
            "Iteration:  55% 198/363 [00:25<00:20,  7.92it/s]\u001b[A\n",
            "Iteration:  55% 199/363 [00:25<00:20,  7.97it/s]\u001b[A\n",
            "Iteration:  55% 200/363 [00:25<00:20,  7.97it/s]\u001b[A\n",
            "Iteration:  55% 201/363 [00:25<00:20,  7.86it/s]\u001b[A\n",
            "Iteration:  56% 202/363 [00:25<00:20,  7.88it/s]\u001b[A\n",
            "Iteration:  56% 203/363 [00:25<00:20,  7.91it/s]\u001b[A\n",
            "Iteration:  56% 204/363 [00:25<00:20,  7.88it/s]\u001b[A\n",
            "Iteration:  56% 205/363 [00:26<00:19,  7.90it/s]\u001b[A\n",
            "Iteration:  57% 206/363 [00:26<00:20,  7.78it/s]\u001b[A\n",
            "Iteration:  57% 207/363 [00:26<00:19,  7.81it/s]\u001b[A\n",
            "Iteration:  57% 208/363 [00:26<00:19,  7.84it/s]\u001b[A\n",
            "Iteration:  58% 209/363 [00:26<00:19,  7.79it/s]\u001b[A\n",
            "Iteration:  58% 210/363 [00:26<00:19,  7.85it/s]\u001b[A\n",
            "Iteration:  58% 211/363 [00:26<00:19,  7.85it/s]\u001b[A\n",
            "Iteration:  58% 212/363 [00:26<00:19,  7.84it/s]\u001b[A\n",
            "Iteration:  59% 213/363 [00:27<00:19,  7.84it/s]\u001b[A\n",
            "Iteration:  59% 214/363 [00:27<00:18,  7.85it/s]\u001b[A\n",
            "Iteration:  59% 215/363 [00:27<00:18,  7.89it/s]\u001b[A\n",
            "Iteration:  60% 216/363 [00:27<00:18,  7.81it/s]\u001b[A\n",
            "Iteration:  60% 217/363 [00:27<00:18,  7.73it/s]\u001b[A\n",
            "Iteration:  60% 218/363 [00:27<00:18,  7.76it/s]\u001b[A\n",
            "Iteration:  60% 219/363 [00:27<00:18,  7.76it/s]\u001b[A\n",
            "Iteration:  61% 220/363 [00:27<00:18,  7.79it/s]\u001b[A\n",
            "Iteration:  61% 221/363 [00:28<00:18,  7.79it/s]\u001b[A\n",
            "Iteration:  61% 222/363 [00:28<00:18,  7.78it/s]\u001b[A\n",
            "Iteration:  61% 223/363 [00:28<00:18,  7.62it/s]\u001b[A\n",
            "Iteration:  62% 224/363 [00:28<00:17,  7.73it/s]\u001b[A\n",
            "Iteration:  62% 225/363 [00:28<00:17,  7.76it/s]\u001b[A\n",
            "Iteration:  62% 226/363 [00:28<00:17,  7.79it/s]\u001b[A\n",
            "Iteration:  63% 227/363 [00:28<00:17,  7.89it/s]\u001b[A\n",
            "Iteration:  63% 228/363 [00:28<00:17,  7.92it/s]\u001b[A\n",
            "Iteration:  63% 229/363 [00:29<00:16,  7.92it/s]\u001b[A\n",
            "Iteration:  63% 230/363 [00:29<00:16,  7.96it/s]\u001b[A\n",
            "Iteration:  64% 231/363 [00:29<00:17,  7.74it/s]\u001b[A\n",
            "Iteration:  64% 232/363 [00:29<00:16,  7.80it/s]\u001b[A\n",
            "Iteration:  64% 233/363 [00:29<00:16,  7.80it/s]\u001b[A\n",
            "Iteration:  64% 234/363 [00:29<00:16,  7.88it/s]\u001b[A\n",
            "Iteration:  65% 235/363 [00:29<00:16,  7.93it/s]\u001b[A\n",
            "Iteration:  65% 236/363 [00:29<00:16,  7.90it/s]\u001b[A\n",
            "Iteration:  65% 237/363 [00:30<00:15,  7.94it/s]\u001b[A\n",
            "Iteration:  66% 238/363 [00:30<00:16,  7.71it/s]\u001b[A\n",
            "Iteration:  66% 239/363 [00:30<00:15,  7.81it/s]\u001b[A\n",
            "Iteration:  66% 240/363 [00:30<00:15,  7.85it/s]\u001b[A\n",
            "Iteration:  66% 241/363 [00:30<00:15,  7.78it/s]\u001b[A\n",
            "Iteration:  67% 242/363 [00:30<00:15,  7.79it/s]\u001b[A\n",
            "Iteration:  67% 243/363 [00:30<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  67% 244/363 [00:30<00:15,  7.87it/s]\u001b[A\n",
            "Iteration:  67% 245/363 [00:31<00:15,  7.84it/s]\u001b[A\n",
            "Iteration:  68% 246/363 [00:31<00:14,  7.92it/s]\u001b[A\n",
            "Iteration:  68% 247/363 [00:31<00:14,  7.94it/s]\u001b[A\n",
            "Iteration:  68% 248/363 [00:31<00:14,  7.98it/s]\u001b[A\n",
            "Iteration:  69% 249/363 [00:31<00:14,  7.81it/s]\u001b[A\n",
            "Iteration:  69% 250/363 [00:31<00:14,  7.86it/s]\u001b[A\n",
            "Iteration:  69% 251/363 [00:31<00:14,  7.90it/s]\u001b[A\n",
            "Iteration:  69% 252/363 [00:32<00:14,  7.92it/s]\u001b[A\n",
            "Iteration:  70% 253/363 [00:32<00:13,  7.89it/s]\u001b[A\n",
            "Iteration:  70% 254/363 [00:32<00:13,  7.88it/s]\u001b[A\n",
            "Iteration:  70% 255/363 [00:32<00:13,  7.96it/s]\u001b[A\n",
            "Iteration:  71% 256/363 [00:32<00:13,  7.96it/s]\u001b[A\n",
            "Iteration:  71% 257/363 [00:32<00:13,  7.74it/s]\u001b[A\n",
            "Iteration:  71% 258/363 [00:32<00:13,  7.80it/s]\u001b[A\n",
            "Iteration:  71% 259/363 [00:32<00:13,  7.69it/s]\u001b[A\n",
            "Iteration:  72% 260/363 [00:33<00:13,  7.78it/s]\u001b[A\n",
            "Iteration:  72% 261/363 [00:33<00:12,  7.90it/s]\u001b[A\n",
            "Iteration:  72% 262/363 [00:33<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  72% 263/363 [00:33<00:12,  7.92it/s]\u001b[A\n",
            "Iteration:  73% 264/363 [00:33<00:12,  7.90it/s]\u001b[A\n",
            "Iteration:  73% 265/363 [00:33<00:12,  7.71it/s]\u001b[A\n",
            "Iteration:  73% 266/363 [00:33<00:12,  7.78it/s]\u001b[A\n",
            "Iteration:  74% 267/363 [00:33<00:12,  7.82it/s]\u001b[A\n",
            "Iteration:  74% 268/363 [00:34<00:12,  7.79it/s]\u001b[A\n",
            "Iteration:  74% 269/363 [00:34<00:12,  7.72it/s]\u001b[A\n",
            "Iteration:  74% 270/363 [00:34<00:11,  7.81it/s]\u001b[A\n",
            "Iteration:  75% 271/363 [00:34<00:11,  7.86it/s]\u001b[A\n",
            "Iteration:  75% 272/363 [00:34<00:11,  7.90it/s]\u001b[A\n",
            "Iteration:  75% 273/363 [00:34<00:11,  7.76it/s]\u001b[A{\"loss\": 0.23938730915635825, \"learning_rate\": 1.6345270890725438e-06, \"epoch\": 2.7548209366391183, \"step\": 1000}\n",
            "05/16/2020 05:21:26 - INFO - transformers.trainer -   Saving model checkpoint to sakamoto_bert/checkpoint-1000\n",
            "05/16/2020 05:21:26 - INFO - transformers.configuration_utils -   Configuration saved in sakamoto_bert/checkpoint-1000/config.json\n",
            "05/16/2020 05:21:27 - INFO - transformers.modeling_utils -   Model weights saved in sakamoto_bert/checkpoint-1000/pytorch_model.bin\n",
            "05/16/2020 05:21:31 - INFO - transformers.trainer -   Saving optimizer and scheduler states to sakamoto_bert/checkpoint-1000\n",
            "\n",
            "Iteration:  75% 274/363 [00:39<02:12,  1.49s/it]\u001b[A\n",
            "Iteration:  76% 275/363 [00:39<01:35,  1.09s/it]\u001b[A\n",
            "Iteration:  76% 276/363 [00:39<01:09,  1.25it/s]\u001b[A\n",
            "Iteration:  76% 277/363 [00:39<00:51,  1.66it/s]\u001b[A\n",
            "Iteration:  77% 278/363 [00:39<00:39,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 279/363 [00:40<00:30,  2.77it/s]\u001b[A\n",
            "Iteration:  77% 280/363 [00:40<00:24,  3.44it/s]\u001b[A\n",
            "Iteration:  77% 281/363 [00:40<00:19,  4.13it/s]\u001b[A\n",
            "Iteration:  78% 282/363 [00:40<00:16,  4.79it/s]\u001b[A\n",
            "Iteration:  78% 283/363 [00:40<00:14,  5.44it/s]\u001b[A\n",
            "Iteration:  78% 284/363 [00:40<00:13,  6.03it/s]\u001b[A\n",
            "Iteration:  79% 285/363 [00:40<00:12,  6.46it/s]\u001b[A\n",
            "Iteration:  79% 286/363 [00:40<00:11,  6.83it/s]\u001b[A\n",
            "Iteration:  79% 287/363 [00:41<00:10,  7.13it/s]\u001b[A\n",
            "Iteration:  79% 288/363 [00:41<00:10,  7.35it/s]\u001b[A\n",
            "Iteration:  80% 289/363 [00:41<00:09,  7.50it/s]\u001b[A\n",
            "Iteration:  80% 290/363 [00:41<00:09,  7.61it/s]\u001b[A\n",
            "Iteration:  80% 291/363 [00:41<00:09,  7.71it/s]\u001b[A\n",
            "Iteration:  80% 292/363 [00:41<00:09,  7.78it/s]\u001b[A\n",
            "Iteration:  81% 293/363 [00:41<00:09,  7.77it/s]\u001b[A\n",
            "Iteration:  81% 294/363 [00:41<00:08,  7.75it/s]\u001b[A\n",
            "Iteration:  81% 295/363 [00:42<00:08,  7.82it/s]\u001b[A\n",
            "Iteration:  82% 296/363 [00:42<00:08,  7.88it/s]\u001b[A\n",
            "Iteration:  82% 297/363 [00:42<00:08,  7.86it/s]\u001b[A\n",
            "Iteration:  82% 298/363 [00:42<00:08,  7.88it/s]\u001b[A\n",
            "Iteration:  82% 299/363 [00:42<00:08,  7.90it/s]\u001b[A\n",
            "Iteration:  83% 300/363 [00:42<00:07,  7.93it/s]\u001b[A\n",
            "Iteration:  83% 301/363 [00:42<00:07,  7.89it/s]\u001b[A\n",
            "Iteration:  83% 302/363 [00:42<00:07,  7.97it/s]\u001b[A\n",
            "Iteration:  83% 303/363 [00:43<00:07,  8.00it/s]\u001b[A\n",
            "Iteration:  84% 304/363 [00:43<00:07,  8.01it/s]\u001b[A\n",
            "Iteration:  84% 305/363 [00:43<00:07,  7.98it/s]\u001b[A\n",
            "Iteration:  84% 306/363 [00:43<00:07,  7.83it/s]\u001b[A\n",
            "Iteration:  85% 307/363 [00:43<00:07,  7.87it/s]\u001b[A\n",
            "Iteration:  85% 308/363 [00:43<00:06,  7.87it/s]\u001b[A\n",
            "Iteration:  85% 309/363 [00:43<00:06,  7.88it/s]\u001b[A\n",
            "Iteration:  85% 310/363 [00:43<00:06,  7.90it/s]\u001b[A\n",
            "Iteration:  86% 311/363 [00:44<00:06,  7.93it/s]\u001b[A\n",
            "Iteration:  86% 312/363 [00:44<00:06,  7.94it/s]\u001b[A\n",
            "Iteration:  86% 313/363 [00:44<00:06,  7.89it/s]\u001b[A\n",
            "Iteration:  87% 314/363 [00:44<00:06,  7.94it/s]\u001b[A\n",
            "Iteration:  87% 315/363 [00:44<00:06,  7.95it/s]\u001b[A\n",
            "Iteration:  87% 316/363 [00:44<00:05,  7.94it/s]\u001b[A\n",
            "Iteration:  87% 317/363 [00:44<00:05,  7.87it/s]\u001b[A\n",
            "Iteration:  88% 318/363 [00:44<00:05,  7.81it/s]\u001b[A\n",
            "Iteration:  88% 319/363 [00:45<00:05,  7.88it/s]\u001b[A\n",
            "Iteration:  88% 320/363 [00:45<00:05,  7.92it/s]\u001b[A\n",
            "Iteration:  88% 321/363 [00:45<00:05,  7.89it/s]\u001b[A\n",
            "Iteration:  89% 322/363 [00:45<00:05,  7.91it/s]\u001b[A\n",
            "Iteration:  89% 323/363 [00:45<00:05,  7.89it/s]\u001b[A\n",
            "Iteration:  89% 324/363 [00:45<00:04,  7.89it/s]\u001b[A\n",
            "Iteration:  90% 325/363 [00:45<00:04,  7.77it/s]\u001b[A\n",
            "Iteration:  90% 326/363 [00:45<00:04,  7.82it/s]\u001b[A\n",
            "Iteration:  90% 327/363 [00:46<00:04,  7.80it/s]\u001b[A\n",
            "Iteration:  90% 328/363 [00:46<00:04,  7.71it/s]\u001b[A\n",
            "Iteration:  91% 329/363 [00:46<00:04,  7.75it/s]\u001b[A\n",
            "Iteration:  91% 330/363 [00:46<00:04,  7.81it/s]\u001b[A\n",
            "Iteration:  91% 331/363 [00:46<00:04,  7.82it/s]\u001b[A\n",
            "Iteration:  91% 332/363 [00:46<00:03,  7.80it/s]\u001b[A\n",
            "Iteration:  92% 333/363 [00:46<00:03,  7.84it/s]\u001b[A\n",
            "Iteration:  92% 334/363 [00:47<00:03,  7.84it/s]\u001b[A\n",
            "Iteration:  92% 335/363 [00:47<00:03,  7.91it/s]\u001b[A\n",
            "Iteration:  93% 336/363 [00:47<00:03,  7.87it/s]\u001b[A\n",
            "Iteration:  93% 337/363 [00:47<00:03,  7.92it/s]\u001b[A\n",
            "Iteration:  93% 338/363 [00:47<00:03,  7.91it/s]\u001b[A\n",
            "Iteration:  93% 339/363 [00:47<00:03,  7.95it/s]\u001b[A\n",
            "Iteration:  94% 340/363 [00:47<00:02,  7.92it/s]\u001b[A\n",
            "Iteration:  94% 341/363 [00:47<00:02,  7.97it/s]\u001b[A\n",
            "Iteration:  94% 342/363 [00:48<00:02,  7.94it/s]\u001b[A\n",
            "Iteration:  94% 343/363 [00:48<00:02,  7.97it/s]\u001b[A\n",
            "Iteration:  95% 344/363 [00:48<00:02,  7.94it/s]\u001b[A\n",
            "Iteration:  95% 345/363 [00:48<00:02,  7.96it/s]\u001b[A\n",
            "Iteration:  95% 346/363 [00:48<00:02,  7.95it/s]\u001b[A\n",
            "Iteration:  96% 347/363 [00:48<00:02,  8.00it/s]\u001b[A\n",
            "Iteration:  96% 348/363 [00:48<00:01,  7.97it/s]\u001b[A\n",
            "Iteration:  96% 349/363 [00:48<00:01,  7.86it/s]\u001b[A\n",
            "Iteration:  96% 350/363 [00:49<00:01,  7.88it/s]\u001b[A\n",
            "Iteration:  97% 351/363 [00:49<00:01,  7.91it/s]\u001b[A\n",
            "Iteration:  97% 352/363 [00:49<00:01,  7.89it/s]\u001b[A\n",
            "Iteration:  97% 353/363 [00:49<00:01,  7.84it/s]\u001b[A\n",
            "Iteration:  98% 354/363 [00:49<00:01,  7.89it/s]\u001b[A\n",
            "Iteration:  98% 355/363 [00:49<00:01,  7.90it/s]\u001b[A\n",
            "Iteration:  98% 356/363 [00:49<00:00,  7.90it/s]\u001b[A\n",
            "Iteration:  98% 357/363 [00:49<00:00,  7.91it/s]\u001b[A\n",
            "Iteration:  99% 358/363 [00:50<00:00,  7.82it/s]\u001b[A\n",
            "Iteration:  99% 359/363 [00:50<00:00,  7.84it/s]\u001b[A\n",
            "Iteration:  99% 360/363 [00:50<00:00,  7.89it/s]\u001b[A\n",
            "Iteration:  99% 361/363 [00:50<00:00,  7.75it/s]\u001b[A\n",
            "Iteration: 100% 363/363 [00:50<00:00,  7.17it/s]\n",
            "Epoch: 100% 3/3 [02:28<00:00, 49.44s/it]\n",
            "05/16/2020 05:21:42 - INFO - transformers.trainer -   \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "05/16/2020 05:21:42 - INFO - transformers.trainer -   Saving model checkpoint to sakamoto_bert\n",
            "05/16/2020 05:21:42 - INFO - transformers.configuration_utils -   Configuration saved in sakamoto_bert/config.json\n",
            "05/16/2020 05:21:43 - INFO - transformers.modeling_utils -   Model weights saved in sakamoto_bert/pytorch_model.bin\n",
            "05/16/2020 05:21:43 - INFO - __main__ -   *** Evaluate ***\n",
            "05/16/2020 05:21:43 - INFO - transformers.trainer -   ***** Running Evaluation *****\n",
            "05/16/2020 05:21:43 - INFO - transformers.trainer -     Num examples = 323\n",
            "05/16/2020 05:21:43 - INFO - transformers.trainer -     Batch size = 8\n",
            "Evaluation: 100% 41/41 [00:01<00:00, 30.37it/s]\n",
            "{\"eval_loss\": 0.8954516975209117, \"eval_mcc\": 0.46153876724837983, \"epoch\": 3.0, \"step\": 1089}\n",
            "05/16/2020 05:21:44 - INFO - __main__ -   ***** Eval results cola *****\n",
            "05/16/2020 05:21:44 - INFO - __main__ -     eval_loss = 0.8954516975209117\n",
            "05/16/2020 05:21:44 - INFO - __main__ -     eval_mcc = 0.46153876724837983\n",
            "05/16/2020 05:21:44 - INFO - __main__ -     epoch = 3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUuMg0rNw_dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp -r sakamoto_bert drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8uICRa5n3t",
        "colab_type": "text"
      },
      "source": [
        "## Do a sequence classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIleRijDl9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjAXSOsX7mqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('sakamoto_bert')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('sakamoto_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlOF-Bd5-Tes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "with open('glue_data/CoLA/test.tsv') as f:\n",
        "  for line in f:\n",
        "    _, sequence = line.strip().split('\\t')\n",
        "    sequences.append(sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJUIrVZ_Aw-n",
        "colab_type": "code",
        "outputId": "e9d9dcaa-baf9-410e-9707-560ee5a953b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "classes = ['aozam3', 'sksk_sskn']\n",
        "\n",
        "for sequence in sequences:\n",
        "    sequence_tensor = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "    classification_logits = model(sequence_tensor)[0]\n",
        "    \n",
        "    results = torch.softmax(classification_logits, dim=1).tolist()[0]\n",
        "\n",
        "    print(sequence)\n",
        "    for i in range(2):\n",
        "        print('{}: {}'.format(classes[i], results[i]))\n",
        "    print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "母 に ハンネ で 呼ば れた ので スマホ 食った\n",
            "aozam3: 0.979850172996521\n",
            "sksk_sskn: 0.020149847492575645\n",
            "\n",
            "外 寒 すぎて デッケェ 冷え ピタ に 包ま れた とき と 全く 同じ 気持ち に なった\n",
            "aozam3: 0.0017393020680174232\n",
            "sksk_sskn: 0.9982606768608093\n",
            "\n",
            "密度 が 高 すぎる ため 少量で 胃 の 質量 を 5000 倍 に し 人間 を 内側 から 破壊 する 餅 と いう 食材 、 本当に 面白い\n",
            "aozam3: 0.006239396519958973\n",
            "sksk_sskn: 0.9937606453895569\n",
            "\n",
            "君 は 私 の 手 に は 負え ない よ …… トホホ …… と 思わ せて くれる 担当 、 好きです\n",
            "aozam3: 0.0006770329200662673\n",
            "sksk_sskn: 0.9993230104446411\n",
            "\n",
            "量 を 重要 視 した ” 食 ” を 行う に あたって 障害 と さ れる 熱 と 冷え は 取り除く と いい らしい です ワザップ に よる と\n",
            "aozam3: 0.0015453067608177662\n",
            "sksk_sskn: 0.9984546899795532\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUb7qdNVPSq",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HaHBCL6WHv8",
        "colab_type": "text"
      },
      "source": [
        "- Transformers\n",
        "    - https://github.com/huggingface/transformers\n",
        "    - https://huggingface.co/transformers/index.html\n",
        "    - https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/huggingface_pytorch-transformers.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1YAYlnVuaHo",
        "colab_type": "text"
      },
      "source": [
        "- CoLA\n",
        "    - https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVN5iwmPVhGK",
        "colab_type": "text"
      },
      "source": [
        "- BERT Japanese pretrained model\n",
        "    - http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn4V3TVdVYjG",
        "colab_type": "text"
      },
      "source": [
        "- Qiita\n",
        "    - https://qiita.com/neonsk/items/27424d6122e00fe632b0\n",
        "    - https://qiita.com/nekoumei/items/7b911c61324f16c43e7e\n",
        "    - https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3\n",
        "    - https://qiita.com/knok/items/9e3b4505d6b8f813943d"
      ]
    }
  ]
}