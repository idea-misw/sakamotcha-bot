{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sakamoto_bert.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok440ey5qnb1",
        "colab_type": "text"
      },
      "source": [
        "# Sakamoto BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kt8TdV0XFo7",
        "colab_type": "text"
      },
      "source": [
        "Fine-tune a Japanese BERT model on a task of Sakamoto-tweet classification. üê≥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_SY2z6yPzsR",
        "colab_type": "text"
      },
      "source": [
        "## Install Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNfAbCr5PSeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!cd transformers;pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52OMOpp4tATI",
        "colab_type": "text"
      },
      "source": [
        "## Download a pre-trained BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf5d3JaoqNr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/JapaneseBertPretrainedModel/Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip\n",
        "!unzip -d bert Japanese_L-12_H-768_A-12_E-30_BPE_transformers.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KgFeuTjoU7i",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK8yV1kKl6bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "# !python download_glue_data.py --data_dir glue_data --tasks all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4lZhZet20r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p glue_data/CoLA\n",
        "!cp drive/My\\ Drive/sakamotcha-bot/data/sakamoto_cola/* glue_data/CoLA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yz3FiaDqA-m",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjqKfim1vRuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U future\n",
        "!cd transformers;pip install -r ./examples/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2TPpoORj83E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python transformers/examples/text-classification/run_glue.py \\\n",
        "    --model_name_or_path bert/Japanese_L-12_H-768_A-12_E-30_BPE_transformers \\\n",
        "    --task_name CoLA \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir glue_data/CoLA \\\n",
        "    --max_seq_length 128 \\\n",
        "    --per_gpu_eval_batch_size=8   \\\n",
        "    --per_gpu_train_batch_size=8   \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 3.0 \\\n",
        "    --output_dir sakamoto_bert/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUuMg0rNw_dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r sakamoto_bert drive/My\\ Drive/sakamotcha-bot/data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J8uICRa5n3t",
        "colab_type": "text"
      },
      "source": [
        "## Do the task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIleRijDl9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjAXSOsX7mqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('sakamoto_bert')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('sakamoto_bert')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlOF-Bd5-Tes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "with open('glue_data/CoLA/test.tsv') as f:\n",
        "  for line in f:\n",
        "    _, sequence = line.strip().split('\\t')\n",
        "    sequences.append(sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJUIrVZ_Aw-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ['aozam3', 'sksk_sskn']\n",
        "\n",
        "for sequence in sequences:\n",
        "    sequence_tensor = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "    classification_logits = model(sequence_tensor)[0]\n",
        "    \n",
        "    results = torch.softmax(classification_logits, dim=1).tolist()[0]\n",
        "\n",
        "    print(sequence)\n",
        "    for i in range(2):\n",
        "        print('{}: {}'.format(classes[i], results[i]))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUb7qdNVPSq",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HaHBCL6WHv8",
        "colab_type": "text"
      },
      "source": [
        "- Transformers\n",
        "    - https://github.com/huggingface/transformers\n",
        "    - https://huggingface.co/transformers/index.html\n",
        "    - https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/huggingface_pytorch-transformers.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1YAYlnVuaHo",
        "colab_type": "text"
      },
      "source": [
        "- CoLA\n",
        "    - https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVN5iwmPVhGK",
        "colab_type": "text"
      },
      "source": [
        "- BERT Japanese pretrained model\n",
        "    - http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT%E6%97%A5%E6%9C%AC%E8%AA%9EPretrained%E3%83%A2%E3%83%87%E3%83%AB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn4V3TVdVYjG",
        "colab_type": "text"
      },
      "source": [
        "- Qiita\n",
        "    - https://qiita.com/neonsk/items/27424d6122e00fe632b0\n",
        "    - https://qiita.com/nekoumei/items/7b911c61324f16c43e7e\n",
        "    - https://qiita.com/kenta1984/items/7f3a5d859a15b20657f3\n",
        "    - https://qiita.com/knok/items/9e3b4505d6b8f813943d"
      ]
    }
  ]
}